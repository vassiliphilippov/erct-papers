British Journal of Educational Psychology (2016), 86, 546–558
© 2016 The British Psychological Society
www.wileyonlinelibrary.com
A randomized controlled trial of an earlyintervention, computer-based literacy program to
boost phonological skills in 4- to 6-year-old children
Paul O’Callaghan1,2*, Aimee McIvor1
, Claire McVeigh3 and
Teresa Rushe1
1
School of Psychology, Queen’s University Belfast, UK
2
Education Authority, Southern Region, Dungannon Educational Psychology Office,
UK
3
SEN Literacy Unit, Stranmillis University College, Belfast, Co. Antrim, UK
Background. Many school-based interventions are being delivered in the absence of
evidence of effectiveness (Snowling & Hulme, 2011, Br. J. Educ. Psychol., 81, 1).
Aims. This study sought to address this oversight by evaluating the effectiveness of the
commonly used the Lexia Reading Core5 intervention, with 4- to 6-year-old pupils in
Northern Ireland.
Sample. A total of 126 primary school pupils in year 1 and year 2 were screened on the
Phonological Assessment Battery 2nd Edition (PhAB-2). Children were recruited from
the equivalent year groups to Reception and Year 1 in England and Wales, and Prekindergarten and Kindergarten in North America.
Methods. A total of 98 below-average pupils were randomized (T0) to either an 8-week
block (x = 647.51 min, SD = 158.21) of daily access to Lexia Reading Core5 (n = 49) or a
waiting-list control group (n = 49). Assessment of phonological skills was completed at
post-intervention (T1) and at 2-month follow-up (T2) for the intervention group only.
Results. Analysis of covariance which controlled for baseline scores found that the Lexia
Reading Core5 intervention group made significantly greater gains in blending, F
(1, 95) = 6.50, p = .012, partial g2 = .064 (small effect size) and non-word reading, F
(1, 95) = 7.20, p = .009, partial g2 = .070 (small effect size). Analysis of the 2-month
follow-up of the intervention group found that all group treatment gains were maintained.
However, improvements were not uniform among the intervention group with 35%
failing to make progress despite access to support. Post-hoc analysis revealed that higher
T0 phonological working memory scores predicted improvements made in phonological
skills.
Conclusions. An early-intervention, computer-based literacy program can be effective
in boosting the phonological skills of 4- to 6-year-olds, particularly if these literacy
difficulties are not linked to phonological working memory deficits.
Effective reading interventions incorporate training in letter–sound knowledge and
phoneme awareness, explicit and systematic phonics instruction, and the application of
*Correspondence should be addressed to Paul O’Callaghan, School of Psychology, Queen’s University Belfast, University Road,
Belfast BT7 1NN, UK (email: pocallaghan02@qub.ac.uk).
DOI:10.1111/bjep.12122
546
these skills to the tasks of reading and spelling (Duff et al., 2014). This explicit teaching of
blending, segmenting, and non-word reading skills to increase efficacy and confidence in
tackling unknown words is all the more essential for at-risk readers given the large body of
evidence now showing the predictive value of letter–sound knowledge and some
phoneme awareness in the development of ‘learning to read’ skills in the early stages
(Snowling & Hulme, 2011).
Research indicates that the earlier an intervention occurs the greater the chance of
remediation (Allen, 2011) and the higher the probability that more entrenched literacy
difficulties in the future can be mitigated (Boscardin, Muthen, Francis, & Baker, 2008).
Currently, the evidence basis for computer-based literacy programs is limited (Brooks,
2013; Cheung & Slavin, 2013; Slavin, Lake, Davis, & Madden, 2011) and mixed (Archer
et al., 2014; Campuzano, Dynarski, Agodini, & Rall, 2009). This is even more evident in
studies of technology-based literacy interventions for children under 8 years of age
(Lankshear & Knobel, 2003; Shannon, Styers, Wilkerson, & Peery, 2015), which the
current study is seeking to address.
Evidence for the effectiveness of computer-based literacy programs currently used in
UK schools comes predominantly from single sample, unpublished, pre- and post-studies
with no control group and no randomization (Brooks, 2013). Brooks (2016) notes the
importance of considering evidence from randomized controlled studies, and an increase
in evidence from studies of this type is demonstrable in his recent review of 19 studies
(Brooks, 2016). Although research evidence is stronger in the United States, arising from a
greater number of controlled studies and randomized trials, findings are ambiguous. One
study program benefits of using a computer-based literacy program on letter identification, word attack skills, and passage comprehension skills for first but not second graders
(Chambers et al., 2011), one found benefits on spelling but not basic literacy skills
(Blachowicz et al., 2009) and another on the reading comprehension of low-achieving
pupils using a blended approach to instruction (Schechter, Macaruso, Kazakoff, & Brooke,
2015).
Similarly varied findings emerged for studies involving the Lexia computer-based
reading skills program both in the United States and in the United Kingdom. In the United
States, matched control studies demonstrated Lexia’s efficacy for all preschoolers but only
kindergarten children with difficulties (Macaruso & Rodman, 2011), improvements in
phonological awareness particularly among children with low pre-test scores (Macaruso
& Walker, 2008) and in both the letter–sound correspondence and word recognition of
low-achieving pupils (Macaruso, Hook, & McCabe, 2006). In the United Kingdom, a quasiexperimental, controlled study involving 106 children found that Lexia was successful in
improving standardized scores in reading for up to 66% of the intervention group
(McMurray, 2013).
Given the variability in research findings and the evidence of effectiveness on
computer-based interventions on some, but not all variables, this study also sought to
explore the different variables that accounted for success in phonological skills. Prior
research, predominantly with older children, identified working memory (McMurray,
2013), gender (Rutter et al., 2004), and language proficiency (Yeung & Chan, 2013)
as mediating factors in literacy difficulties and intervention response, and this study
sought to explore whether these variables were also relevant for younger populations
too.
In summary, many questions still remain regarding the effectiveness of computerassisted literacy interventions. Given the variability in findings, the use of a randomized
controlled trial (RCT) is an important contribution to the literature (Snowling & Hulme,
Early-intervention computer literacy program RCT 547
2011). This study is, to the authors’ knowledge, the first participant-level, RCT of Lexia
with Year 1 and 2 pupils conducted to date.
The first research question sought to test whether the intervention group would show
statistically significant improvements in blending, phoneme segmentation, and non-word
reading at T1 when compared to the control group. The second research question sought
to examine whether gains made on the intervention were uniform across all participants
and if not, to determine the factors that would predict participant progress.
Method
Trial design
This was a parallel-group, RCT with a no-treatment, wait-list control group. The study ran
from December 2014 to June 2015. Every child who met eligibility criteria agreed to
participate in the study (see Figure 1) and were randomized to either the Experimental
group (8 weeks of daily 20- to 30-min sessions of the intervention) or a wait-list control
group (standard classroom teaching in line with the statutory Northern Irish curriculum
and supplemented with both synthetic and linguistic phonics programmes). Children
were assessed individually pre-intervention (T0), post-intervention (T1), and at 2-month
follow-up (T2) (intervention group only). Ethical approval was given by the School of
Psychology Research Ethics Committee at Queen’s University, Belfast, and written
parental consent and verbal pupil assent were provided for all participants.
Participants and setting
The study took place in two town-based primary schools in Northern Ireland. Schools
were chosen based on their ability to provide pupils with access to a multicomputer
information and communications technology (or ICT) suite and their focus on raising
whole-school literacy levels in their school development plan. School A had a registered
pupil population of 250, 46% of whom were eligible for free school meals. School B had a
registered population of 547, 44% of whom were eligible for free school meals. The study
was run in conjunction with the Educational Psychology Service and the School of
Psychology and was overseen by a qualified Educational and Child Psychologist with
research experience as lead investigator in school-based RCTs in the past. In keeping with
previous research which showed the benefit for staff training and support on the efficacy
of computer-based interventions (Archer et al., 2014), pre-intervention set-up and
product introductory tutorials and ongoing technical support were provided to both
schools by LexiaUK Ltd.
Participant details are listed in Table 1. A total of 126 children were screened to
identify those with the weakest reading skills. Inclusion criteria for the study were (1)
being in a mainstream Year 1 or Year 2 class, (2) having a standard score of 90 or less on any
of the four subtests of the four Phonological Assessment Battery 2nd Edition (PhAB-2)
subtests assessed (low average to below average range). In Northern Ireland, the
compulsory school age is 4. Therefore children in Years 1 and 2 there are within the same
age range as those in Reception and Y1 in England and Wales, and in Pre-kindergarten and
Kindergarten in North America. Exclusion criterion was having scores of 0 on all four
subtests (due to concerns about floor effects). The 14 excluded pupils were then offered a
more intensive, separate programme of literacy support. To keep the trial naturalistic,
children with English as an Additional Language or pupils on the school’s SEN register
were not excluded. Of the 126 children screened, 98 met inclusion criteria and all were
548 Paul O’Callaghan et al.
invited to participate in the RCT study. All agreed and provided parental consent. The
pupils ranged in age from 4 to 6 (x = 63 months, SD = 9.5).
Based on the post-intervention group outcome means in a quasi-experimental study of
Lexia in Northern Ireland (McMurray, 2013), we calculated the minimum sample size to
adequately power the study to be 40 per group, at a power level of .80 and an alpha value
of .05 (ClinCalc.com).
Procedure
Classroom assistants and the school SENCo were trained by the second author in the
administration of the PhAB-2 (Gibbs & Bodman, 2014) in the week prior to the scheduled
testing. During this training, staff were provided with video tapes of standardized
administration, and were given an opportunity to administer the four subtests and have
any questions on test administration answered. The importance of consistency was
stressed, and assessors were observed administering the subtests to ensure consistency of
administration across assessors.
Assessed for eligibility (n = 126)
Enrolment
Excluded (n = 28)
• 14 scored above 90 on all variables
• 14 had raw scores of ‘0’ on all variables
Randomized (n = 98)
Allocated to Wait-List Control group (n = 49)
• Received allocated intervention (n = 49)
• Discontinued intervention (n = 0)
Allocated to Lexia intervention group (n = 49)
• Received allocated intervention (n = 49)
• Discontinued intervention (n = 2)
Allocation (T1)
Included (n = 49)
• Lost to post-test (n = 2)
Analysed (n = 49)
Included (n = 49)
• Lost to post-test (n = 2)
Post-intervention (T1)
Included (n = 49)
• Lost to follow-up (n = 4)
2-Month Follow-Up (T2)
Primary Analysis
Analysed (n = 49)
Figure 1. Consort diagram showing flow of participants through the trial.
Early-intervention computer literacy program RCT 549
Tests were administered over 3 days in December (T0), April (T1) and June (T2) in
private reading rooms in each school to keep disruptions and external noise to a
minimum. To ensure consistency throughout the intervention, data collection at each
time period was allocated to the same assessor. The first author enrolled participants
while the second author used simple randomization to generate the allocation sequence
(www.random.org) and assigned participants to the two groups. There were no changes
to the methods or outcomes after trial commencement and the trial proceeded as per the
protocol.
Measures
To assess phonological skills the Phonological Assessment Battery Second Edition (PhAB2) were used. The PhAB-2 was chosen because (1) it was recently standardized for the age
range of interest, (2) it measures both phonological processing (e.g., blending subtest)
and phonological production (e.g., non-word Reading), (3) it provides standardized
scores of Phonological Working Memory (we were interested in seeing whether this
variable could predict improvements made on the intervention over time), and (4) it
contains a standardized protocol for both test administration and scoring, detailed in the
test manual (Gibbs & Bodman, 2014). We used four subtests on the PhAB-2: Blending
subtest (combining sounds to make a spoken word, e.g., /k/, /æ/, /t/ = cat), Phoneme
Segmentation subtest (separating spoken words into their constituent phonemes, e.g.,
car = /k/ + /a˞/) The retroflex (‘r-coloured’) version of this phoneme is provided here as in
Northern Ireland the majority of regional dialects are rhotic. In addition, the Phonological
Working Memory subtest (repeating a series of non-words, e.g., narraf) and Non-Word
Reading subtest (decoding unfamiliar strings of letters as sounds that might form a word,
e.g., tib) were administered also. In line with McMurray (2013) eligibility criteria were set
as having a standard score of <90 on any of the variables measures at T0 and improvements
over time were measured using raw score changes. This was done because it was felt that
raw scores were a more objective measure of change in outcomes over time than
standardized scores with populations at the lowest end of the normative sample range.
In 2013, the PhAB-2 was standardized with a sample of 773 (4- to 11-year-olds) children
in England, Scotland and Wales (Gibbs & Bodman, 2014). Internal consistency for the four
subtests used ranged from .76 (Phonological Working Memory) to .96 (Blending).
Evidence of construct validity was shown in increases of score with age and intercorrelations between the PhAB-2 Primary tests, while strong correlations of .721 and .738
Table 1. Descriptive data for the intervention and wait-list control group in the study
Lexia group
(n = 49)
Wait-list group
(n = 49)
F-value
or v2 p-valuea
Number of boys, n (%) 26 (53) 21 (43) 1.022 .312
Number of year 1 children, n (%) 23 (47) 25 (51) 0.163 .686
Number of EAL children, n (%) 16 (33) 18 (37) 0.180 .671
Age of participants, x (SD) 62.78 (10.75) 63.76 (8.17) 0.258 .613
T0 blending scores, x (SD) 4.45 (5.87) 4.61 (6.24) 0.018 .894
T0 segmentation scores, x (SD) 4.00 (4.18) 3.12 (3.87) 1.163 .284
T0 NW reading scores, x (SD) 2.18 (4.68) 2.27 (4.38) 0.008 .929
Note. a
One-way ANOVAs (confidence interval: 95%) measured baseline differences of continuous
variables and chi-square tests measured baseline differences for categorical variables.
550 Paul O’Callaghan et al.
were found between the test of non-word Reading and the York Assessment of Reading
Comprehension and Single Word Reading Test, respectively.
Intervention
The intervention group received daily, individual, adult-supervised, 20- to 30-min blocks
of computer-based support on Lexia Reading Core5 program for 8 weeks
(x = 647.51 min, SD = 158.21). Lexia was chosen due to its growing use in UK schools
by children with literacy needs and English as an Additional Language (www.lex
iauk.co.uk) and its preliminary research findings suggesting its effectiveness (Brooks,
2013, 2016). This reading skills program allows pupils to work independently in a
structured, sequential manner. When pupils log-on to Lexia for the first time, they take an
Auto Placement test to determine their level and then progress through graded exercises
in phonological awareness, phonics, fluency, vocabulary, and comprehension. However,
to ensure even progress, the Lexia program blocks advancement to higher levels until a
prescribed set of minimum units in all five areas are completed correctly. In addition to
tracking the time an individual child spends on Lexia, it also tracks the number of units
each child correctly completes and flags areas of difficulty where a pupil fails to grasp a
concept or make progress despite access to additional activities to remediate this
difficulty. The Lexia program targets skills in rhyming, blending and segmenting, letter–
sound correspondence, ‘b’, ‘d’, ‘p’ confusable letters, short and long vowels, spelling
rules, high-frequency sight words, fluency, vocabulary development, timed silent reading
and listening, and reading comprehension.
The Lexia online program can be supplemented with offline, teacher-led resources for
individual or small group instruction. Lexia lessons consist of structured, teacherdelivered lessons which are designed to address skills based on performance on the online
activities, as identified by the teacher using online reports generated by the program. Skill
Builders are offline, pencil and paper activities which can be completed at the end of each
online activity. These are designed to complement and extend work completed through
the online Lexia program. This study examined use of the online Lexia program only.
Data analysis
To control for baseline differences between the intervention and wait-list control group,
an analysis of covariance (ANCOVA), controlling for baseline scores, was used and partial
eta squared (g2
) and Cohen’s d effect sizes were recorded.
Comparisons between the intervention group and control group were conducted at
T0 (baseline testing) and T1 only. Results indicated equivalent performance at baseline
testing. The control group received their intervention after T1 analysis was conducted and
demonstrated the effectiveness of the intervention.
Repeated-measures ANOVAs were used to measure within subject effects for the
intervention group on all three variables over time from T0 to T1 and then at T2 while
linear regression analysis was used to identify the demographic, procedural and baseline
variables that could predict improvements in phonological skills.
Four pupils were unable to be tested at T1 and 4 pupils from the intervention group
were unable to be tested at T2 but were included in the outcome analysis (intention-totreat analysis. Except in the case of the participants mentioned above who were absent for
T1 or T2 testing, there were no other missing values in this study. Bonferroni adjustment
Early-intervention computer literacy program RCT 551
of significance levels was applied for all multiple comparisons (p < .0167). Statistical
analyses were conducted using IBM SPSS version 22 (IBM, 2013).
Results
Baseline characteristics
Baseline characteristics of participants in the two groups are presented in Table 1.
Randomization resulted in no significant difference on age, gender, year group, English as
an Additional Language status (or EAL status) or any T0 measure.
Recruitment began in December 2014, with T1 testing in April 2015 and P2 testing in
June 2015. The trial was ended after the intervention group had received one block of
intervention support. Two pupils discontinued the intervention (due to difficulties using a
mouse and frustration and anxiety caused by this and the other one due to poor
attendance) having accessed 23 and 51 min, respectively. However, in order not to
compromise the integrity of the randomization, the pupils’ scores were still included in T1
and T2 analysis of the intervention group. Meanwhile, three pupils at T1 and four pupils
from the intervention group at T2 were absent on the day of testing and their scores were
included using a ‘last value carried forward’ method.
Prior to analysis, scatterplots were used to measure linearity and Levene’s test
indicated homogeneity of variance for all variables.
An ANCOVA (covarying for baseline scores) found that the Lexia intervention group
were better able to blend sounds, F(1, 95) = 6.50, p = .012, partial g2 = .064 and read
non-sense words, F(1, 95) = 7.20, p = .009, partial g2 = .070 than the wait-list control
group after the intervention with medium effect sizes reported (g2 > .0588) (see
Table 2).
Furthermore, these gains were maintained at T2 with repeated-measures ANOVAs (see
Table 3), demonstrating an ‘intervention over time’ effect for the Lexia group on all
blending, phoneme segmentation, and non-word reading, respectively, F(2, 47) = 27.09,
p < .001, partial g2 = .535, F(2, 47) = 30.70, p < .001, partial g2 = .566 and
F(2, 47) = 22.88, p < .001, partial g2 = .493.
Inspection of the data of the intervention group at T1 testing indicated that the gains
made by the intervention group as a whole were not evenly distributed and that 35% of the
intervention group (17/49) made no improvements on two of the three outcome variables.
Regression analysis (see Table 4) indicated that phonological working memory scores
successfully predicted improvements in blending scores in the Lexia group (p = .001).
Meanwhile, the intervention was shown to be equally successful for boys and girls, pupils
from School A or School B, pupils who had English as a first or as an additional language or
pupils that spent a large or small amount of time on the intervention.
Discussion
Interpretation
This RCT supports the findings of previous quasi-controlled studies, which found that
Lexia can be effective in helping reading delayed children (Macaruso et al., 2006) and
children with literacy difficulties linked to phonological deficits (McMurray, 2013). It adds
to the growing evidence basis for the effectiveness of both early-intervention (Hatcher
et al., 2006; Macaruso & Walker, 2008; Schwartz, 2005) and computer-based literacy
programs (McMurray, 2013; Shannon et al., 2015). However, unlike previous studies, this
552 Paul O’Callaghan et al.
Table 2. Analysis of covariance for blending, segmentation, and non-word reading at T1
Variable
Intervention (n = 49)
Mean (SD)
Control (n = 49)
Mean (SD)
Value F(1, 95) p
Effect size (
g2
)
(Cohen’s da
) T0 T1 Diff T0 T1 Diff
Blending 4.45 (5.87) 9.18 (6.51) 4.74 (4.78) 4.61 (6.24) 7.02 (6.68) 2.41 (4.38) 6.50 .012 .064 (d = .36)
Phoneme segmentation 4.00 (4.18) 5.61 (4.49) 1.61 (3.46) 3.12 (3.87) 3.78 (4.01) 0.65 (3.78) 3.467 .066 .035 (d = .23)
Non-word reading 2.18 (4.68) 5.63 (6.73) 3.45 (4.82) 2.27 (4.38) 3.57 (5.57) 1.31 (2.82) 7.20 .009 .070 (d = .35)
Note. aCohen’s d was calculated using the difference in gains scores divided by the pooled post-test standard deviations.
Early-intervention computer literacy program RCT 553
study tested the effectiveness of a phonics-based computer-based literacy program with
children in their first and second year of school, using an RCT, which makes these findings
an important addition to the field of early-intervention, literacy support programmes.
Secondly, while the intervention was shown to improve blending and non-word
reading skills, it was less effective for phoneme segmentation skills. This is in line with
previous research which found that the kindergarten Lexia group made greater progress
than the control group on reading accuracy but not on phoneme segmentation (Macaruso
& Walker, 2008). One hypothesized explanation for this lack of evidence is visual channel
overload (Sakar & Ercetin, 2005). Visual channel overload occurs when verbal, auditory,
and visual information obtained from a text becomes too much for a person’s working
memory to process. Although all of the subtests in this study were administered
orally, phoneme segmentation was the only subtest which contained both aural and visual
input.
Thirdly, although nearly two-thirds of the intervention group found the Lexia
intervention to be beneficial, 35% of this group failed to make progress despite access to
this intensive phonics-based intervention. This finding of a significant minority of children
whose literacy difficulties are persistent despite remediation was also found in both the
McMurray (2013) and Hatcher et al. (2006) studies and offers further evidence for the
obstructive role of working memory deficits in early literacy acquisition (Alloway et al.,
2005; McMurray, 2013). It also demonstrates the importance of a multimodal literacy
intervention where ICT is supplemented by the mediation of a skilled adult (Brooks, 2013)
who can remediate pupil-specific literacy problems identified by the ICT program.
Table 4. Regression analysis for intervention group on difference in blending scores at T1
Coefficients
Model
Unstandardized
coefficients Standardized
coefficients
t Sig.
95.0% Confidence interval for
B
B Std. error b Lower bound Upper bound
(Constant) 7.361 5.594 1.316 .196 18.659 3.937
Age 0.021 0.77 .048 0.277 .783 0.177 0.134
School 0.531 1.518 .056 0.350 .728 2.535 3.597
Gender 1.539 1.352 .162 1.138 .262 1.191 4.269
EngOrEAL 1.752 1.553 .174 1.128 .266 1.385 4.888
Class 1.165 1.773 .123 0.657 .515 4.745 2.416
Time 0.007 0.005 .219 1.436 .159 0.003 0.016
Phonological
WM score, T0
0.578 0.163 .479 3.554 .001 0.249 0.906
Table 3. Descriptive data for intervention group on blending, segmentation, and NW reading at T0, T1,
T2
N Variable Mean SD Variable Mean SD Variable Mean SD
49 BlendT0 4.45 5.87 SegT0 4.00 4.18 NWRT0 2.18 4.68
49 BlendT1 9.18 6.51 SegT1 5.61 4.49 NWRT1 5.63 6.73
49 BlendT2 10.9 6.65 SegT2 7.53 4.04 NWRT2 7.55 6.93
554 Paul O’Callaghan et al.
Finally, the finding that time spent on the programme was not a significant predictor of
outcome is in line with the finding of McMurray (2013). McMurray (2013) also found that
time spent on Lexia did not significantly contribute to the amount of variance in final
reading scores. Instead, the findings of the present study and those of McMurray (2013)
indicate that children’s progress on the Lexia program contributed to the amount of
variance in final reading scores, as indicated in McMurray’s study by level and in the
present study by score. The present authors postulate that a ceiling period of time can be
reached within a session and once this is reached a pupil cannot make more progress
within a session. This suggestion is strengthened by the views of the children in
McMurray’s (2013) study who note that they reach a point where they become ‘stuck’ on a
Level. The authors also postulate that the optimal period of time spent on the program is
likely to be developmentally appropriate and in line with a child’s attention span, and
individual differences.
Limitations
This current study had some important limitations. Firstly, it used a wait-list control design
which meant that only within-treatment effects were available at T2. This decision was
taken because the authors felt an ethical responsibility to provide literacy support to the
wait-list control group identified with literacy difficulties as soon as we possibly could.
Given the restricted time frame of the study and the restricted access to individual user
licences from Lexia for the duration of the study, the only available time to provide the waitlist group with support was after the intervention group had received their 8-week block.
The restricted time frame for the study also limited the length of time available for
follow-up. While the authors accept a 2-month time frame falls short of the 6- to 24-month
follow-up of other literacy intervention studies (Duff et al., 2014), we felt that it was better
to include a follow-up test at least equivalent to the length of time of the intervention in
order to monitor progress or fall-back.
Thirdly, participants did not access the adult-mediated support using the scripted
lesson plans (Lexia Lessons) and practice worksheets (Skill Builders) generated by the
Lexia program to help pupils who had not grasped a literacy concept being taught
electronically. This was an omission, which occurred due to timetable limitations, but
which could be planned for in future research through an examination of the use of these
supplementary resources in conjunction with the online program. Importantly, the role of
the teacher must be stressed in critically evaluating the most effective use of any such
resources at an individual pupil level. This may be particularly important given the
growing evidence of the impact of adult mediation in determining the success of
computer-based programs (Brooks, 2013; Savage et al., 2010). While the present results
are positive in terms of the efficacy of the program for the majority of participating
children, it may be noted that the expertise and critical professional judgement of the class
teacher is likely to be a crucial factor in its most effective deployment.
Generalizability
Despite the limitations above, the study had many important strengths. Firstly, it sought to
subject well-intentioned educational practices to vigorous evaluation (Duff et al., 2014)
using practitioner-led evidence-based research. The study adopted the most rigorous
research method available (Snowling & Hulme, 2011), something sorely lacking in the
field of literacy interventions (Brooks, 2013; Snowling & Hulme, 2011). To improve the
Early-intervention computer literacy program RCT 555
external validity of the study, children with English as an Additional Language and pupils
on the SEN register were also included. The study sought to target literacy difficulties as
early as possible, something that research has identified as both achievable (Hatcher et al.,
2006) and cost-beneficial (Allen, 2011).
With recent cuts in school budgets, pupils are now less likely to access within school
literacy support, placing an even greater strain on external literacy support services,
lengthening waiting lists and further delaying access to much needed assistance. Although
not a panacea for all literacy difficulties, computer-based interventions can provide a
strategic opportunity for children to access early-intervention, intensive, phonics-based
support in a format that children report to be enjoyable and motivating (McMurray, 2013).
If literacy difficulties are caused by underlying phonological deficits in the absence of
significant working memory deficits, access to computer-based support could just
provide the literacy boost some children need to catch-up with peers and access classbased literacy instruction. This prevents difficulties becoming entrenched and offers a
quick and early solution allowing classroom literacy learning to continue.
Future research is needed to examine which components of the Lexia Reading Core5
program are most successful in boosting phonological and letter–sound knowledge, the
impact of additional adult mediation on progress made on the program, the impact of
Lexia on subsequent reading and spelling skills of participants and whether progress in
phonological skills is sustained by children engaging with this computer-based intervention over a longer period of time.
Conclusion
This RCT demonstrated that a computer-based, early-intervention literacy program
boosted the phonological skills of children, resulting in significantly higher performance
on blending and non-word reading tasks as compared with the control group.
Furthermore, these gains in performance were maintained by the intervention group
when assessed again at 2-month follow-up. However, post-hoc analysis showed that effect
sizes were small and that gains made by the intervention group were not spread evenly
across participants with approximately 35% of the intervention group failing to make
significant gains despite access to the intervention. Future research should investigate the
cognitive factors impacting on the performance of children who are not seen to make
progress on such interventions. In considering why this may be the case, it may be noted
that multiple regression analysis conducted for this research indicated that pre--
intervention phonological working memory scores were a key predictor of gains made
within the intervention group. The findings overall show promising initial results from a
RCT of a computer-based literacy intervention for young children.
However, it also demonstrates that while a majority of children involved will make
progress, there are significant minorities of children who do not make gains on this type of
program, which has been reported elsewhere in the literature (McMurray, 2013; Hatcher
et al., 2006).
Finally, in deciding whether or not to utilize such a program with a pupil, practitioners
may wish to consider phonological working memory scores when deciding on the
specific literacy support package offered to struggling pupils, as pre-intervention
phonological working memory scores were seen to be a key predictor of gains made in
reading skills within the intervention group.
556 Paul O’Callaghan et al.
Acknowledgements
The authors would like to thank David Thompson, Jill Wharton, Sean Dillon, Siobhan Murphy,
Kathy O’Neill, and Eimear Loughran for their valuable contribution to this work.
References
Allen, G. (2011). Early intervention, the next steps: An independent report to her Majesty’s
government. London: The Stationery Office.
Alloway, T. P., Gathercole, S. E., Adams, A. M., Willis, C., Eaglen, R., & Lamont, E. (2005). Working
memory and phonological awareness as predictors of progress towards early learning goals at
school entry. The British Journal of Developmental Psychology, 23, 417–426. doi:10.1348/
026151005X26804
Archer, K., Savage, R., Sanghera-Sidhu, S., Wood, E., Gottardo, A., & Chen, V. (2014). Examining the
effectiveness of technology use in classrooms: A tertiary meta-analysis. Computers & Education,
78, 140–149. doi:10.1016/j.compedu.2014.06.001
Blachowicz, C. L., Bates, A., Berne, J., Bridgman, T., Chaney, J., & Perney, J. (2009). Technology and
at-risk young readers and their classrooms. Reading Psychology, 30, 387–411. doi:10.1080/
02702710902733576
Boscardin, C. K., Muthen, B., Francis, D. J., & Baker, E. L. (2008). Early identification of reading
difficulties using heterogeneous developmental trajectories. Journal of Educational
Psychology, 100(1), 192. doi:10.1037/0022-0663.100.1.192
Brooks, G. (2013). What works for children and young people with literacy difficulties: The
effectiveness of intervention schemes (4th ed.). The Dyslexia-SpLD Trust.
Brooks, G. (2016). What works for children and young people with literacy difficulties: The
effectiveness of intervention schemes (5th ed.). The Dyslexia-SpLD Trust.
Campuzano, L., Dynarski, M., Agodini, R., & Rall, K. (2009). Effectiveness of reading and
mathematics software products: Findings from two student cohorts. NCEE 2009-4041.
Washington, DC: National Center for Education Evaluation and Regional Assistance.
Chambers, B., Slavin, R. E., Madden, N. A., Abrami, P., Logan, M. K., & Gifford, R. (2011). Small-group,
computer-assisted tutoring to improve reading outcomes for struggling first and second graders.
The Elementary School Journal, 111, 625–640. doi:10.1086/659035
Cheung, A. C., & Slavin, R. E. (2013). Effects of educational technology applications on reading
outcomes for struggling readers: A best-evidence synthesis. Reading Research Quarterly, 48,
277–299. doi:10.1002/rrq.50
Duff, F. J., Hulme, C., Grainger, K., Hardwick, S. J., Miles, J. N., & Snowling, M. J. (2014). Reading and
language intervention for children at risk of dyslexia: A randomised controlled trial. Journal of
Child Psychology and Psychiatry, 55, 1234–1243. doi:10.1111/jcpp.12257
Gibbs, S., & Bodman, S. (2014). Phonological assessment battery (2nd ed.). London, UK: GL
Assessment.
Hatcher, P. J., Hulme, C., Miles, J. N., Carroll, J. M., Hatcher, J., Gibbs, S., ... Snowling, M. J. (2006).
Efficacy of small group reading intervention for beginning readers with reading-delay: A
randomised controlled trial. Journal of Child Psychology and Psychiatry, 47, 820–827.
doi:10.1111/j.1469-7610.2005.01559.x
IBM Corp. (2013). IBM SPSS statistics for windows, version 22.0. Armonk, NY: Author.
Lankshear, C., & Knobel, M. (2003). New technologies in early childhood literacy research: A review
of research. Journal of Early Childhood Literacy, 3(1), 59–82. doi:10.1177/146879.
84030031003
Macaruso, P., Hook, P., & McCabe, R. (2006). The efficacy of computer-based supplementary
phonics programs for advancing reading skills in at-risk elementary students. Journal of
Research in Reading, 29, 162–172. doi:10.1111/j.1467-9817.2006.00282.x
Early-intervention computer literacy program RCT 557
Macaruso, P., & Rodman, A. (2011). Efficacy of computer-assisted instruction for the development of
early literacy skills in young children. Reading Psychology, 32, 172–196. doi:10.1080/
02702711003608071
Macaruso, P., & Walker, A. (2008). The efficacy of computer-assisted instruction for advancing
literacy skills in kindergarten children. Reading Psychology, 29, 266–287. doi:10.1080/
02702710801982019
McMurray, S. (2013). An evaluation of the use of Lexia Reading software with children in Year 3,
Northern Ireland (6-to 7-year olds). Journal of Research in Special Educational Needs, 13(1),
15–25. doi:10.1111/j.1471-3802.2012.01238.x
Rutter, M., Caspi, A., Fergusson, D., Horwood, L. J., Goodman, R., Maughan, B., ... Carroll, J. (2004).
Sex differences in developmental reading disability: New findings from 4 epidemiological
studies. JAMA, 291, 2007–2012. doi:10.1001/jama.291.16.2007
Sakar, A., & Ercetin, G. (2005). Effectiveness of hypermedia annotations for foreign language
reading. Journal of Computer Assisted Learning, 21(1), 28–38. doi:10.1111/j.1365-
2729.2005.00108.x
Savage, R. S., Erten, O., Abrami, P., Hipps, G., Comaskey, E., & van Lierop, D. (2010).
ABRACADABRA in the hands of teachers: The effectiveness of a web-based literacy
intervention in grade 1 language arts programs. Computers & Education, 55, 911–922.
doi:10.1016/j.compedu.2010.04.002
Schechter, R., Macaruso, P., Kazakoff, E. R., & Brooke, E. (2015). Exploration of a blended learning
approach to reading instruction for low SES students in early elementary grades. Computers in
the Schools, 32, 183–200. doi:10.1080/07380569.2015.1100652
Schwartz, R. M. (2005). Literacy learning of at-risk first-grade students in the reading recovery early
intervention. Journal of Educational Psychology, 97, 257. doi:10.1037/0022-0663.97.2.257
Shannon, L. C., Styers, M. K., Wilkerson, S. B., & Peery, E. (2015). Computer-assisted learning in
elementary reading: A randomized control trial. Computers in the Schools, 32(1), 20–34.
doi:10.1080/07380569.2014.969159
Slavin, R. E., Lake, C., Davis, S., & Madden, N. A. (2011). Effective programs for struggling readers: A
best-evidence synthesis. Educational Research Review, 6(1), 1–26. doi:10.1016/
j.edurev.2010.07.002
Snowling, M. J., & Hulme, C. (2011). Evidence-based interventions for reading and language
difficulties: Creating a virtuous circle. British Journal of Educational Psychology, 81(1), 1–23.
doi:10.1111/j.2044-8279.2010.02014.x
Yeung, S. S., & Chan, C. K. K. (2013). Phonological awareness and oral language proficiency in
learning to read English among Chinese kindergarten children in Hong Kong. British Journal of
Educational Psychology, 83, 550–568. doi:10.1111/j.2044-8279.2012.02082.x
Received 16 March 2016; revised version received 1 July 2016
558 Paul O’Callaghan et al.