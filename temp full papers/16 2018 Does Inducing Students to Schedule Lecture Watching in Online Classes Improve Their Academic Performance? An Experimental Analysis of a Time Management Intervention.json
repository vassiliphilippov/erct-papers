{
  "title": "Does Inducing Students to Schedule Lecture Watching in Online Classes Improve Their Academic Performance? An Experimental Analysis of a Time Management Intervention",
  "authors": "Rachel Baker, Brent Evans, Qiujie Li, Bianca Cung",
  "url": "https://doi.org/10.1007/s11162-018-9521-3",
  "slug": "baker-et-al-2018-scheduling-online-classes",
  "abstract": "Through a randomized control trial of students in a for-credit online course at a public 4-year university, this paper tests the efficacy of a scheduling intervention aimed at improving students’ time management. While the intervention initially improved quiz scores for students with lower self-reported time management skills, those early positive effects did not persist over the full 5-week term. The study discusses potential mechanisms, including procrastination and cramming, though no strong effects on these behaviors were found. Overall, the results suggest that simple scheduling prompts may briefly enhance performance but may not sustain long-term gains if they are discontinued.",
  "publication_date": "2018-01-01",
  "erct_level": 0,
  "rct": true,
  "criteria": {
    "c": {
      "analysis": "First Paragraph: The ERCT ‘C’ criterion requires that randomization occur at the class level (or at least not student-level within the same classroom) unless an approved exception applies (e.g., personal tutoring). In the paper, the authors state: “We employ a randomized control trial testing the effects of a ... scheduling intervention on course achievement ... We randomly assigned students into treatment and control groups” (p. 6). Here, randomization is clearly done at the individual student level within a single online course.\n\nSecond Paragraph: The authors do not mention randomizing entire classes or multiple sections. Instead, they note: “A total of 176 students enrolled ... 157 students were randomly assigned” (pp. 7–8). This indicates the random assignment was effectively ‘student-by-student’ in one course.\n\nThird Paragraph: The ERCT standard’s exception for individualized tutoring or personal one-to-one instruction does not apply here, because this is not a one-on-one tutoring program. It is an email-based scheduling prompt delivered to each student in an online lecture course. There is no evidence that the entire class or entire schools were assigned as units; hence contamination remains possible within the same class if students discussed their scheduling practice.\n\nConclusion Paragraph: Because this was a student-level RCT in a single class, and no valid exception applies, the requirement that entire classes (or schools) be randomized is not satisfied. Therefore, criterion C is not met.",
      "met": false,
      "explanation": "Randomization occurred at the individual-student level, not at the class or school level, and the personal-tutoring exception does not apply.",
      "quote": "“We employ a randomized control trial ... We randomly assigned students into treatment and control groups.” (p. 6)"
    },
    "e": {
      "analysis": "First Paragraph: The ‘E’ criterion requires use of a standardized exam-based assessment (a widely recognized, externally developed test). In this study, the main outcomes are weekly quiz scores and the final course grade. The authors report: “...the effect of encouraging students to schedule their coursework on academic performance in an online, for-credit postsecondary course” (p. 2). They specify, “We focus our analyses on the weekly quiz scores ... and final course grade...” (p. 11).\n\nSecond Paragraph: There is no indication that these weekly quizzes or final exam are externally validated standardized tests such as a state or national exam. Instead, the instructors themselves designed the quizzes, or at least the institution’s course exam was used. For instance, the authors note: “Each week required students to watch five lecture videos with in-video quizzes ... complete daily homework assignments ... and take weekly quizzes” (p. 8). These weekly quizzes appear to be course-specific assessments, not a recognized standardized measure.\n\nThird Paragraph: Since no evidence shows that a widely recognized standardized test (e.g., statewide or nationwide exam) was used, the paper does not fulfill the ‘E - Exam-based Assessment’ requirement. The quizzes and exam are limited to that single course’s structure.\n\nConclusion Paragraph: Because the assessments described are custom to the course and not standard external tests, criterion E is not met.",
      "met": false,
      "explanation": "Only instructor-created or course-specific quizzes were used, rather than a recognized standardized exam.",
      "quote": "“We focus our analyses on the weekly quiz scores and final course grade as opposed to the daily homework scores... we find positive treatment effects on initial quiz grades.” (pp. 11–12)"
    },
    "t": {
      "analysis": "First Paragraph: The ‘T’ criterion requires that the intervention be implemented for at least one full academic term, typically 3–4 months. In this paper, the course was a 5-week summer class: “We conducted our study in an online undergraduate STEM course lasting 5 weeks...” (p. 8).\n\nSecond Paragraph: The authors emphasize the intensive but short duration of this course: “The course was in the summer term, was offered online, and conferred full credit ... Each is only 5 weeks long” (p. 8). This timeframe is well below the typical length of an academic semester or term, which the ERCT Standard envisions as about 3+ months.\n\nThird Paragraph: Because the entire study spanned only 5 weeks, it does not satisfy the minimum requirement of a one-term intervention.\n\nConclusion Paragraph: The study’s short 5-week window is insufficient for a full academic term, so T is not met.",
      "met": false,
      "explanation": "The intervention lasted only 5 weeks in a summer course, which is shorter than a standard academic term.",
      "quote": "“We conducted our study in an online undergraduate STEM course lasting 5 weeks in a selective, public 4-year university.” (p. 8)"
    },
    "d": {
      "analysis": "First Paragraph: Criterion D requires that the control group be well-documented with demographic information, baseline performance, and conditions. The authors provide a thorough description of how the control group was assigned and what they received: “Students were randomly assigned into treatment (N=79) and control (N=78) groups ... The control students received emails ... with a link to a survey asking them which web browser they used...” (pp. 7–8).\n\nSecond Paragraph: Table 1 in the paper presents detailed baseline characteristics for both the treatment and control groups, including age, SAT scores, race/ethnicity, and self-reported time management measures. The authors explicitly test for balance across these variables, stating: “We observe only one variable having a significant p-value at conventional levels ... providing additional confidence that randomization produced equivalent groups” (p. 10).\n\nThird Paragraph: They also describe the ‘business-as-usual’ environment for the control group: “In order to ensure that the control students had an equal number of contacts from the instructor ... control students received an email from the course instructor ... The suggestion was delivered ... to isolate the effect of the scheduling survey” (p. 9). This clarifies the control group conditions (web browser or headphones surveys) and how many participants were in that condition.\n\nConclusion Paragraph: The paper provides baseline data, group size, and clear delineation of the control group’s alternative survey. Hence the control group is documented in detail, satisfying D.",
      "met": true,
      "explanation": "They present baseline demographics, performance, and a clear description of control group activities (placebo survey).",
      "quote": "“A total of 176 students enrolled in this course ... 157 students were randomly assigned... The control students received an email ... The authors tested for baseline equivalences (Table 1).” (pp. 7–10)"
    },
    "s": {
      "analysis": "First Paragraph: ‘S’ requires that entire schools, rather than classes or students, be randomized. The paper’s randomization was within a single course, as the authors explain: “We employed a randomized control trial ... with 79 in treatment and 78 in control ... in an online class” (pp. 2, 6–7).\n\nSecond Paragraph: There is no mention of multiple schools or entire schools being assigned to different arms. Instead, the focus is one group of individuals at one institution, within the same class. The trial design does not involve randomizing schools or entire institutions.\n\nThird Paragraph: Because randomization is at the student level, and not at the school level, the ‘S’ criterion is not met.\n\nConclusion Paragraph: The authors do not describe any approach to randomize entire schools, so S is not met.",
      "met": false,
      "explanation": "They randomized individual students, not entire schools, so the design does not satisfy school-level RCT.",
      "quote": "“We randomly assigned 157 students who were enrolled in the online class into treatment or control groups.” (p. 8)"
    },
    "a": {
      "analysis": "First Paragraph: The ‘A’ criterion requires measuring the impact on all main subjects or a justified set of subjects if it is a specialized intervention in a vocational or advanced setting. The authors focus exclusively on one course’s performance: “We focus on the weekly quiz scores in an online STEM course” (p. 2).\n\nSecond Paragraph: This single-course setting is inherently limited to a single subject: an upper-level STEM topic requiring calculus. No mention is made of measuring other subjects or broader academic domains.\n\nThird Paragraph: Because they only assessed outcomes (quiz grades, final exam) in this one subject, they do not measure all main subjects taught at the institution.\n\nConclusion Paragraph: As a result, the ‘AllExams’ requirement is not fulfilled. The study only looks at one course outcome without covering other subject areas.",
      "met": false,
      "explanation": "They exclusively assessed performance in one STEM course and did not test all main subjects.",
      "quote": "“Our outcomes are weekly quiz scores and final course grade in an online STEM class.” (p. 2)"
    },
    "y": {
      "analysis": "First Paragraph: ‘Y’ requires the study to last at least one academic year. The authors repeatedly note the course spanned 5 weeks: “We conducted our study in a 5-week summer term” (p. 8). That is obviously much shorter than a typical year.\n\nSecond Paragraph: The standard typically sees a year as approximately nine or ten months of instruction. Five weeks is far shorter.\n\nThird Paragraph: Because the intervention was not carried out for a full academic year, the ‘Y’ requirement is not met.\n\nConclusion Paragraph: The total duration is well below a year, so Y is not satisfied.",
      "met": false,
      "explanation": "Implementation only covered 5 weeks in summer, not a full academic year.",
      "quote": "“The course was in the summer term ... Each is only 5 weeks long.” (p. 8)"
    },
    "b": {
      "analysis": "First Paragraph: ‘B’ requires that if the treatment group gets extra resources (time, funding, or other advantages), the control group also receives an equivalent amount of time or budget for ‘business as usual.’ In this study, the main difference is receiving an email with a scheduling survey vs. a ‘placebo’ email that asks about web browsers/headphones. Both groups received instructor contact and a small extra-credit incentive.\n\nSecond Paragraph: The authors specify that the control students “received an equal number of contacts from the instructor” (p. 9). They also confirm that each group could earn the same small extra credit for answering the survey, ensuring the control group had an equivalent chance at extra credit. There is no mention of additional resource allocation or budget to the treatment group beyond a scheduling prompt.\n\nThird Paragraph: Because no additional resources (time, tutoring, money, etc.) were given specifically to the treatment group, there was no imbalance to correct. The control group was effectively balanced with the same frequency of instructor messages and the same extra credit.\n\nConclusion Paragraph: With the minimal nature of the intervention (just a scheduling prompt) and a matched placebo survey for the control, B is met. There is no resource/time imbalance that remains unaddressed.",
      "met": true,
      "explanation": "No significant resource difference existed; both groups received identical instructor contacts and extra credit opportunities.",
      "quote": "“In order to ensure ... control students had an equal number of contacts from the instructor ... The control students received an email with a survey about web browsers... (p. 9)”"
    },
    "g": {
      "analysis": "First Paragraph: ‘G’ requires tracking participants until their graduation from the educational level in question (e.g., finishing high school or finishing their undergraduate program). This paper reports data only from a 5-week summer course and final exam.\n\nSecond Paragraph: The authors do not mention any follow-up after the term ended. They do not track whether students eventually completed their degrees or advanced to graduation: “Our employment of a randomized control trial enables us to causally assess the effect of encouraging scheduling on a variety of achievement outcomes ... no difference in overall course scores” (p. 2).\n\nThird Paragraph: Because the study ends with the course final, there is no extended or graduation-based follow-up.\n\nConclusion Paragraph: The short window of data collection means the ‘Graduation Tracking’ requirement is not satisfied.",
      "met": false,
      "explanation": "They only measured outcomes within a 5-week window and did not follow students until graduation.",
      "quote": "“We observe no statistically significant difference between the control and treatment groups ... and no difference in overall course scores.” (p. 14)"
    },
    "r": {
      "analysis": "First Paragraph: ‘R’ requires that the intervention be replicated independently by a different team. The authors describe previous scheduling interventions in MOOCs but do not indicate an independent replication of this same study by other researchers.\n\nSecond Paragraph: They reference three prior studies in MOOCs (Baker et al. 2016; Kizilcec et al. 2016; Patterson 2014), but these are not formal, independent replications of the same design in a separate for-credit context. In fact, Baker is also an author of this paper.\n\nThird Paragraph: No statement indicates a second team performed the same scheduling intervention under new leadership or in a different institution. The authors do not claim any independent replication or mention a separate study verifying these findings.\n\nConclusion Paragraph: The paper therefore does not meet ‘R’ for reproduced replication by an external group.",
      "met": false,
      "explanation": "No mention of a separate independent replication by different researchers in another context.",
      "quote": "“Although many studies have previously explored ... The three prior studies took place in MOOCs ... The current study extends these contexts.” (pp. 3–5)"
    },
    "i": {
      "analysis": "First Paragraph: ‘I’ requires that the study be conducted by researchers independent of the intervention’s original designers. Here, the scheduling intervention was devised by the authors themselves, in collaboration with the instructor.\n\nSecond Paragraph: The text states: “We employed a randomized control trial testing the effects of a scheduling intervention ... We had access to many student behaviors within the course” (p. 2). The authors are intimately involved in both the design (the scheduling prompt) and the data collection.\n\nThird Paragraph: No disclaimers are provided indicating external evaluation or that the entire intervention and data analysis was performed by a completely separate research team. Indeed, this seems like an internal effort by the authors.\n\nConclusion Paragraph: Because the same group that designed the scheduling approach implemented and analyzed it, independence is not demonstrated, so I is not met.",
      "met": false,
      "explanation": "The authors themselves designed and delivered the intervention, with no external group conducting the study.",
      "quote": "“The goal of this paper is to test the efficacy of a scheduling intervention in an online postsecondary course. We employ a randomized control trial ...” (p. 2)"
    },
    "p": {
      "analysis": "First Paragraph: ‘P’ requires that the study be pre-registered before data collection, with a protocol accessible to confirm no selective reporting. In the paper, there is no mention of a formal pre-registration or registry platform.\n\nSecond Paragraph: Typically, pre-registered RCTs reference a site such as ClinicalTrials.gov or OSF. This paper does not mention any registration ID or date, nor does it say “Our study was pre-registered.”\n\nThird Paragraph: Given this omission, we must conclude there was no official pre-registration or at least none reported.\n\nConclusion Paragraph: Hence the ‘P’ criterion for pre-registration is not met.",
      "met": false,
      "explanation": "The authors do not mention any formal pre-registration or registry entry made prior to data collection.",
      "quote": null
    }
  }
}
