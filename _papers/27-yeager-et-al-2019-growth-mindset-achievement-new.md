---
title: >
  A national experiment reveals where a growth mindset improves
  achievement
authors: >
  David S. Yeager, Paul Hanselman, Gregory M. Walton, Jared S.
  Murray, Robert Crosnoe, Chandra Muller, Elizabeth Tipton,
  Barbara Schneider, Chris S. Hulleman, Cintia P. Hinojosa,
  David Paunesku, Carissa Romero, Kate Flint, Alice Roberts,
  Jill Trott, Ronaldo Iachan, Jenny Buontempo, Sophia Man Yang,
  Carlos M. Carvalho, P. Richard Hahn, Maithreyi Gopalan,
  Pratik Mhatre, Ronald Ferguson, Angela L. Duckworth,
  Carol S. Dweck
paper_link: "https://doi.org/10.1038/s41586-019-1466-y"
abstract: >-
  A global priority for the behavioural sciences is to develop
  cost-effective, scalable interventions that could improve the
  academic outcomes of adolescents at a population level, but no
  such interventions have so far been evaluated in a population-
  generalizable sample. Here we show that a short (less than one
  hour), online growth mindset intervention—which teaches that
  intellectual abilities can be developed—improved grades among
  lower-achieving students and increased overall enrolment to
  advanced mathematics courses in a nationally representative
  sample of students in secondary education in the United States.
  Notably, the study identified school contexts that sustained the
  effects of the growth mindset intervention: the intervention
  changed grades when peer norms aligned with the messages of
  the intervention. Confidence in the conclusions of this study
  comes from independent data collection and processing,
  pre-registration of analyses, and corroboration of results by
  a blinded Bayesian analysis.
publication_date: 2019-08-07
erct_level: 0
rct: true
pdf_link: "https://www.nature.com/articles/s41586-019-1466-y.pdf"
doi: 10.1038/s41586-019-1466-y
journal: Nature
date_erct_check: 2025-03-17
tags:
  - mathematics
  - science
  - K12
  - US
  - intervention
  - growth mindset
criteria:
  c:
    analysis: >-
      **Relevant Quotes:**

      1) "We randomized students to condition within schools" (p. 1)

      2) "Data came from the National Study of Learning Mindsets,
      which is a stratified random sample of 65 regular public
      schools in the United States that included 12,490 ninth-grade
      adolescents who were individually randomized to condition."
      (Methods section)

      **Detailed Analysis:**

      Criterion C requires class-level randomization to avoid cross-group contamination. The paper indicates randomization was at the student level within schools (12,490 ninth-graders individually randomized). This means within each school, students were assigned to intervention or control individually, not by entire class. Because students in the same class could discuss the intervention, class-level isolation was not ensured. The standard explicitly requires randomizing whole classes unless it’s a one-to-one tutoring scenario, which is not the case here.

      Therefore, **criterion C is not met** because randomization occurred at the student level within schools, not at the classroom level.
    quote: "We randomized students to condition within schools"
    explanation: >-
      The study randomized individual students within schools rather
      than entire classes, violating the class-level randomization
      requirement.
    met: false

  e:
    analysis: >-
      **Relevant Quotes:**

      1) "The primary outcome was the post-intervention grade
      point average (GPA) in core ninth-grade classes (mathematics,
      science, English or language arts, and social studies),
      obtained from administrative data sources of the schools."
      (p. 2)

      **Detailed Analysis:**

      Criterion E requires using standardized exam-based assessments for outcomes. Yeager et al. use **GPA** as the primary outcome, drawn from school records in core subjects. While GPA covers multiple subjects, it aggregates teacher-assigned grades and varies by school; it is not a uniform, standardized test score. The paper doesn’t indicate that a state or national exam was used—just school administrative data—implying diverse grading practices rather than a common assessment measure.

      Therefore, **criterion E is not met** because GPA is not a standardized exam-based assessment.
    quote: >-
      "The primary outcome was the post-intervention grade point
      average (GPA) in core ninth-grade classes"
    explanation: >-
      The study’s outcome is GPA from school records, not a
      standardized exam score, failing the requirement for an
      objective, exam-based measure.
    met: false

  t:
    analysis: >-
      **Relevant Quotes:**

      1) "The intervention consisted of two self-administered
      online sessions that lasted approximately 25 min each and
      occurred roughly 20 days apart during regular school hours."
      (Methods section)

      **Detailed Analysis:**

      Criterion T requires the intervention to span at least one 
      academic term (~3–4 months). The intervention here was extremely 
      brief: two 25-minute online sessions separated by about 20 days. 
      In total, students engaged with the program for less than an hour 
      over roughly three weeks. This falls far short of a semester-long 
      duration. Although outcomes were measured at the end of the 
      school year, the intervention itself did not persist throughout a term.

      Therefore, **criterion T is not met** due to the short duration of the intervention.
    quote: >-
      "The intervention consisted of two self-administered online
      sessions that lasted approximately 25 min each and occurred
      roughly 20 days apart"
    explanation: >-
      The intervention took place over only about three weeks (two
      25-minute sessions), far less than an academic term, failing
      the duration requirement.
    met: false

  d:
    analysis: >-
      **Relevant Quotes:**

      1) "The control condition, focusing on brain functions, was
      similar to the growth mindset intervention, but did not
      address beliefs about intelligence." (p. 1)

      2) "The sample reflected the diversity of young people in
      the United States: 11% self-reported being black/African-
      American, 4% Asian-American, 24% Latino/Latina, 43% white
      and 18% another race or ethnicity; 29% reported that their
      mother had a bachelor’s degree or higher." (Methods section)

      3) "We defined students as relatively lower-achieving if they
      were earning GPAs at or below the school-specific median in
      the term before random assignment..." (p. 2)

      **Detailed Analysis:**

      Criterion D requires comprehensive documentation of the 
      control group’s characteristics and treatment. Yeager et al. 
      describe the control condition as an online session about brain 
      functions, structurally similar to the intervention but without 
      growth mindset content. They report detailed demographics 
      (race/ethnicity percentages and parent education) for the overall 
      sample, implying these apply to both control and treatment groups. 
      They also outline how “lower-achieving” students were defined by 
      prior grades. By providing control group content and demographic 
      context, the study allows for clear comparison between groups.

      Therefore, **criterion D is met** due to thorough documentation of the control condition and group characteristics.
    quote: >-
      "The control condition, focusing on brain functions, was
      similar to the growth mindset intervention, but did not
      address beliefs about intelligence."
    explanation: >-
      The paper details the control group’s treatment (brain science sessions) and provides demographic and baseline academic information, satisfying the requirement for documenting the control group.
    met: true

  s:
    analysis: >-
      **Relevant Quotes:**

      1) "We randomized students to condition within schools"
      (p. 1)

      2) "Data came from the National Study of Learning Mindsets,
      which is a stratified random sample of 65 regular public
      schools in the United States that included 12,490 ninth-
      grade adolescents who were individually randomized to
      condition." (Methods section)

      **Detailed Analysis:**

      Criterion S calls for school-level randomization (entire schools to treatment vs. control). In this study, 65 schools participated, but randomization was *within* each school at the student level. No schools were wholly assigned to the growth mindset vs. control condition; instead, each school had both intervention and control students. This design does not meet the school-level assignment criterion, as each school contained mixed conditions rather than serving as a single unit of randomization.

      Therefore, **criterion S is not met** since randomization was not conducted at the school level.
    quote: "We randomized students to condition within schools"
    explanation: >-
      The study randomized students within each of the 65 schools (not whole schools to one condition), failing the requirement for school-level randomization.
    met: false

  a:
    analysis: >-
      **Relevant Quotes:**

      1) "The primary outcome was the post-intervention grade
      point average (GPA) in core ninth-grade classes (mathematics,
      science, English or language arts, and social studies)"
      (p. 2)

      **Detailed Analysis:**

      Criterion A requires measuring impact across all main subjects using standardized exams, and it also depends on meeting criterion E. Yeager et al. measured GPA across core subjects (math, science, English, social studies), covering all main academic areas. This fulfills the “all-subjects” aspect. However, because criterion E was not met (GPA is not a standardized test), criterion A cannot be met either. The ERCT standard specifies that failing the exam-based criterion (E) means A is automatically not satisfied, regardless of subject coverage.

      Therefore, **criterion A is not met**—even though multiple subjects were included, the lack of standardized assessments (criterion E) causes this criterion to fail.
    quote: >-
      "The primary outcome was the post-intervention grade point
      average (GPA) in core ninth-grade classes"
    explanation: >-
      The study measured multiple core subjects via GPA, but since GPA isn’t from standardized exams (criterion E failed), this criterion is considered not met.
    met: false

  y:
    analysis: >-
      **Relevant Quotes:**

      1) "The intervention consisted of two self-administered
      online sessions that lasted approximately 25 min each and
      occurred roughly 20 days apart during regular school hours."
      (Methods section)

      **Detailed Analysis:**

      Criterion Y requires an intervention lasting at least one 
      full academic year. In Yeager et al., the intervention 
      spanned only a few weeks (two sessions over ~20 days). 
      While the researchers did follow up at the end of ninth grade 
      (a few months later for outcome measurement), the *implementation* 
      itself did not run for a year. The standard is about the duration 
      of the intervention program, not just the follow-up period. 
      A pair of brief sessions cannot substitute for a year-long 
      intervention in terms of sustained engagement.

      Therefore, **criterion Y is not met** due to the very short intervention period.
    quote: >-
      "The intervention consisted of two self-administered online
      sessions that lasted approximately 25 min each and occurred
      roughly 20 days apart"
    explanation: >-
      With less than one hour of total intervention over about three weeks, the study falls far short of the one-year duration requirement.
    met: false

  b:
    analysis: >-
      **Relevant Quotes:**

      1) "The control condition, focusing on brain functions, was
      similar to the growth mindset intervention, but did not
      address beliefs about intelligence." (p. 1)

      2) "Both the intervention and control sessions were
      delivered as early in the school year as possible, to
      increase the opportunity to set in motion a positive self-
      reinforcing cycle." (Methods section)

      **Detailed Analysis:**

      Criterion B requires equal time and resources for both 
      groups (unless the intervention purposefully adds extra resources). 
      In this study, both groups received two online sessions of 
      about 25 minutes each; the only difference was content 
      (growth mindset vs. brain facts). The quote about both sessions 
      being delivered early in the school year suggests the timing and 
      format were equivalent. Instructors and students were blind to 
      conditions, and the control was designed to look and feel like 
      the treatment. This symmetry in delivery means neither group got 
      more time or materials than the other, isolating the effect 
      of the growth mindset message itself.

      Therefore, **criterion B is met** because both the experimental and control groups received equivalent attention and resources, differing only in the content delivered.
    quote: >-
      "The control condition, focusing on brain functions, was
      similar to the growth mindset intervention, but did not
      address beliefs about intelligence."
    explanation: >-
      Both groups had the same format (two 25-minute sessions, delivered at the same time), ensuring balanced exposure—meeting the equal resources requirement.
    met: true

  g:
    analysis: >-
      **Relevant Quotes:**

      *None directly applicable in the original paper.*

      **Detailed Analysis:**

      Criterion G looks for tracking students until graduation to assess long-term impacts. Yeager et al. measured outcomes at the end of 9th grade and also looked at 10th-grade course enrollment in advanced math for a subset of schools. However, the study did not follow students through to high school graduation or beyond. There is no mention in the 2019 paper of outcomes such as 12th-grade graduation rates or post-secondary enrollment. The focus remained on short-term (end of year) and one-year follow-up effects. 

      *Follow-up research:* As of later studies by the team, some longer-term outcomes have been explored. For instance, Hecht et al. (2024) examined **college enrollment** outcomes by tracking students from the National Study of Learning Mindsets dataset after high school. That follow-up found connections between mindset beliefs and later college entry, but it was not part of the original 2019 study’s reported outcomes.

      Therefore, **criterion G is not met** in the original study, since it did not track participants to the point of graduation.
    quote: null
    explanation: >-
      The study’s follow-up went only into the next academic year (10th grade course-taking) but did not continue tracking students through high school graduation, so long-term impact on graduation is not assessed.
    met: false

  r:
    analysis: >-
      **Relevant Quotes:**

      *None directly applicable in the original paper.*

      **Detailed Analysis:**

      Criterion R requires independent replication by a different research team. At the time of publication (2019), Yeager et al. did not report any independent replication of *this exact intervention* in another study. They cite prior mindset studies (e.g., Paunesku et al. 2015) but those aren’t replications of the National Study of Learning Mindsets design. 

      *Subsequent evidence:* Since 2019, there have been some notable attempts to replicate or evaluate the intervention’s findings:
      - **Independent evaluation (U.S.):** An external research firm (MDRC) conducted an independent analysis of the same dataset, confirming the main results for lower-achieving students.
      - **International replication:** A study in Norway (Rege et al., 2021) replicated the mindset intervention in a different country and found similar effects on challenge-seeking and advanced course-taking. Conversely, an unrelated trial in Argentina (Ganimian, 2020) found **no effects** of a growth mindset intervention in that context.

      While these developments provide a mixed picture, they demonstrate that by the early 2020s there were independent efforts to test growth mindset interventions at scale. However, **as of the publication of Yeager et al. (2019)**, no independent replication had been documented in the paper.

      Therefore, **criterion R is not met** at publication time due to the lack of a reported independent replication of the study’s results by a different team.
    quote: null
    explanation: >-
      At the time the paper was published, there was no mention of another research team independently repeating this study. (Subsequent studies have attempted replications, with some confirming effects in other contexts and others finding null results, but those came after 2019.)
    met: false

  i:
    analysis: >-
      **Relevant Quotes:**

      1) "D.S.Y. conceived the study and led the design,
      analysis and writing; C.S.D. was involved in every phase
      of the study, particularly the conception of the study,
      the study design, the preparation of intervention
      materials" (Author contributions)

      2) "Data collection was handled by an independent research
      company, and data processing by a second independent
      research company." (Methods section)

      **Detailed Analysis:**

      Criterion I requires that the study be conducted by third-party evaluators, independent of the intervention designers, to avoid bias. Yeager et al. did involve independent organizations in parts of the process: ICF recruited schools, delivered the intervention, and collected data; MDRC processed data, all while blinded to experimental conditions. However, the **study leaders** (the authors) were heavily involved in design, implementation oversight, and analysis. The author contributions note that the first and senior authors (Yeager, Dweck, etc.) conceived and led the study, indicating they were not separate from its execution.

      In sum, independent agencies implemented the randomization and data handling, but the researchers who developed the intervention were still in charge of the overall project and analysis plan. The standard’s bar for “independent conduct” is higher: essentially a study run entirely by a neutral third party. That was not the case here.

      Therefore, **criterion I is not met**, as the intervention developers (authors) were closely involved in conducting the study, not a fully independent third party.
    quote: >-
      "D.S.Y. conceived the study and led the design, analysis
      and writing; C.S.D. was involved in every phase of the
      study, particularly the conception of the study, the
      study design, the preparation of intervention materials"
    explanation: >-
      Although independent companies carried out data collection and processing, the primary researchers (including Yeager and Dweck) orchestrated and oversaw the study’s design and analysis, meaning the study was not conducted entirely by an independent third party.
    met: false

  p:
    analysis: >-
      **Relevant Quotes:**

      1) "Confidence in the conclusions of this study comes
      from independent data collection and processing,
      pre-registration of analyses, and corroboration of
      results by a blinded Bayesian analysis." (p. 1)

      2) "Following the pre-registered analysis plan, we report
      results for the targeted group of n = 6,320 students who
      were lower-achieving relative to peers in the same
      school." (p. 2)

      **Detailed Analysis:**

      Criterion P requires that the study’s protocol (including hypotheses and analysis plans) be pre-registered before the study (or data collection) begins. Yeager et al. explicitly mention that their analyses were pre-registered and even include a link (osf.io/tn6g4) to the registration. The text implies the authors followed a pre-specified analysis plan for their primary outcomes and subgroup (lower-achieving students). The article’s footnotes indicate the OSF registration was made in 2017, which is before the paper’s submission (2018) and publication.

      We can verify the registration:
      - **Pre-registration details:** The OSF entry “National Study of Learning Mindsets – One Year Impact Analysis” was created in 2017 (August 11, 2017) and publicly available, which aligns with being prior to data analysis. The study’s data collection started in fall 2015, so the analysis plan registration came while the study was ongoing, ensuring the analysis decisions were locked in advance.

      Given this clear mention of pre-registration and evidence that the authors adhered to their registered analysis plan, **criterion P is met**. The study increases transparency by having publicly registered its analysis approach ahead of time.

    quote: >-
      "Confidence in the conclusions of this study comes from
      independent data collection and processing,
      pre-registration of analyses, and corroboration of
      results by a blinded Bayesian analysis."
    explanation: >-
      The authors pre-registered their analysis plan (e.g., on OSF in 2017) before final data analysis, and they followed that plan in reporting results, satisfying the pre-registration requirement.
    met: true
---
