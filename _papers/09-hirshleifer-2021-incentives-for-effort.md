---
title: "Incentives for Effort or Outputs? A Field Experiment to Improve
  Student Performance"
authors: "Sarojini R. Hirshleifer"
paper_link: "https://escholarship.org/uc/item/9hz5b8g9"
abstract: >-
  This randomized experiment implemented with school children in India directly
  tests an input incentive (rewards for effort on learning modules) against an
  output incentive (rewards for test performance) and a control. Students in the
  input incentive treatment performed substantially better on a follow-up test
  than both the control and the output incentive treatment. The author
  attributes these results to increased effort exerted by students on the
  interactive online modules, facilitated by more frequent and immediate
  rewards. The paper discusses cost-effectiveness, student present-bias, and
  other potential mechanisms influencing why input-based incentives can
  improve short-run math outcomes.
publication_date: 2021-10-12
erct_level: 0
rct: true
pdf_link: "https://escholarship.org/content/qt9hz5b8g9/qt9hz5b8g9_noSplash_d5dc508f9a649002495879899e85c7d9.pdf?t=r4u5c1"
doi: "10.5072/FK23J3JR55"
journal: "CEGA Working Papers"
date_erct_check: "2025-03-09"
tags:
  - mathematics
  - K12
  - EdTech platform
  - pay-to-learn
  - Asia
criteria:
  c:
    met: true
    explanation: >-
      Randomization was performed at the classroom level, which is
      acceptable for 'Class-level RCT.'
    quote: >-
      "The study relies on classroom-level randomization. Specifically, 45 4th
      through 6th grade classrooms … were randomized into treatments…" (p.
      12)
    analysis: >-
      First, we look for whether randomization was done at the class level (or a
      stronger school level). The paper explicitly states: "The study relies on
      classroom-level randomization…" (p. 12). Further details confirm that 45
      classrooms (4th through 6th grade) were divided among treatments, including
      two incentive groups and one control group. The paper's design notes, "Classrooms
      were randomized into treatments using a partial rotation design over two
      units." In other words, the researchers assigned treatments by classroom,
      not by individual student or by school. This class-level allocation helps
      avoid within-class contamination. For example, it means that all students in
      a given classroom either receive the input incentive, the output incentive,
      or no incentive (control). By ensuring that entire classrooms share the same
      treatment, the design reduces the chance that children in the same room will
      spuriously share materials or coaching meant only for the treatment group.
      Thus, from the standpoint of ERCT Standard's 'Class-level RCT' criterion, the
      study meets the requirement.
  e:
    met: false
    explanation: >-
      They use custom tests drawn from the KA Lite module question bank
      rather than a widely recognized standardized exam.
    quote: >-
      "In each unit, the output and outcome tests… are drawn from the question pools
      associated with the core modules." (p. 8)
    analysis: >-
      The ERCT Standard requires the use of a standardized, externally recognized exam
      to measure student outcomes. Here, the main outcome measure is a custom-built
      unit test on the KA Lite platform: "The main outcome measure is a second test
      that is administered at the end of the unit… The test draws from the same
      question pools as the modules." (p. 8, 9). The author clarifies that these
      questions come directly from the software's internal question bank, tailored to
      the content that students practiced. Because these tests were constructed
      around the interactive modules within the study context, they do not align
      with a recognized, large-scale standardized exam (such as a national or state
      test). Instead, they are bespoke assessments embedded within the
      intervention's technology platform.
  t:
    met: false
    explanation: >-
      The paper describes an intervention of two 6-week units (12 weeks
      total) rather than clearly spanning a full recognized term.
    quote: >-
      "Two units of KA Lite content were included … each unit taking six weeks on
      average." (p. 7)
    analysis: >-
      To meet 'Term Duration,' the study intervention should last at least one full
      academic term, typically around 3-4 months. In this paper, the researcher
      notes: "Two units of KA Lite content were included in the study, with each unit
      taking six weeks on average." (p. 7). She further describes that the experiment
      ran from shortly after the mid-year break until the end of the school year,
      which seems to cover approximately 12 weeks total (~6 weeks per unit). Although
      12 weeks is about 3 months, the paper does not explicitly state that this
      coincided precisely with a formal academic term or semester. The design
      appears to revolve around these two six-week units of content, culminating in
      an outcome test after each unit. This timing is shorter than or just on the
      borderline for what many schools define as a standard academic term. The text
      does not indicate that the period was recognized as a formal 'semester.'
      Therefore, the evidence leans toward this criterion not being fully
      satisfied.
  d:
    met: true
    explanation: >-
      They clearly define the no-incentive control, document its baseline
      characteristics, and specify it as receiving usual instruction plus the same
      modules (but no rewards).
    quote: >-
      "The study tests an input incentive… output incentive… and a control. The sample
      is balanced at baseline… The control group receives no rewards." (pp. 2, 10;
      Table SA2)
    analysis: >-
      Under 'Documented Control Group,' the study must provide a clear description of
      the control group's composition, baseline performance, and conditions. The
      paper explains: "The study tests a student incentive for the input activity
      against both an output incentive and a no-incentive control." (p. 2). The
      author also includes a baseline test, and Table SA2 and further references
      outline how the sample was balanced at baseline across the three groups.
      Additionally, the paper states that in the control group, students used the same
      KA Lite modules in class, but "the only difference across the treatments is which
      activity is rewarded" (p. 10). Thus, the control group is well documented.
  s:
    met: false
    explanation: >-
      They implemented the randomization at the classroom, not school, level.
    quote: >-
      "The study relies on classroom-level randomization… [we used] 45 4th through 6th
      grade classrooms…" (p. 12)
    analysis: >-
      For 'School-level RCT,' entire schools (rather than just classes) must be
      randomized. However, this paper emphasizes: "The study relies on classroom-level
      randomization" (p. 12). With 45 classrooms drawn from multiple schools in Mumbai
      and Pune, the authors randomly assigned each classroom to one of three
      conditions: input incentive, output incentive, or control. Since randomization
      did not occur at the whole-school level, but rather among classrooms within
      schools, the S criterion is not met.
  a:
    met: false
    explanation: >-
      They only measure outcomes in mathematics; no other subjects' performance
      is tracked.
    quote: >-
      "All students are assigned the same interactive learning modules ... 
      and test at the end of the unit ... 
      The main outcome measure is a second test at the end of the unit." (p. 1–2)
    analysis: >-
      Under the 'AllExams' criterion, a study should measure impact on all major
      subjects taught at that level, typically using standard exam-based measures.
      In contrast, this paper focuses solely on math learning. There is no mention
      of measuring reading, languages, science, or other subjects in the official
      outcome data.
  y:
    met: false
    explanation: >-
      They only ran the intervention and measurements for about 12 weeks total,
      not a full academic year.
    quote: >-
      "Two units… each taking about six weeks… from mid-year break to the end of the
      school year." (p. 7)
    analysis: >-
      The 'Year Duration' requirement states the intervention must last at least one
      full academic year. Here, the paper clarifies that the experiment took place
      from after a mid-year break until the end of the school year, focusing on "two
      units" of six weeks each. That schedule totals around 12 weeks, not a complete
      ~9-10 month school year. Therefore, the Y criterion is not met.
  b:
    met: true
    explanation: >-
      Since the study’s primary objective is to assess the impact of additional rewards on outcomes,
      the control group intentionally receives only the standard “business as usual” inputs. The extra
      resources in the treatment groups constitute the treatment itself; therefore, the control group being
      unenhanced is by design and does not indicate an imbalance.
    quote: >-
      "All students complete the same modules and tests, thus the only difference across 
      the treatments is which activity is rewarded." (p. 8)
    analysis: >-
      In this study, every group receives the identical core educational content, class time, and instruction.
      The treatment groups receive additional tangible rewards as the experimental intervention. Since the
      research question specifically tests whether these extra rewards affect outcomes, the control group’s
      receipt of the standard input is appropriate. This design isolates the effect of the additional resource,
      satisfying the balanced control group requirement.
  g:
    met: false
    explanation: >-
      The study ends measurements within the same school year; it does not
      follow students through graduation.
    quote: >-
      "The experiment began after students returned from the mid-year break and 
      continued to the end of the school year." (p. 7)
    analysis: >-
      This criterion asks whether the study continued tracking students until they
      graduated from their current school level. The paper collects only short-term
      outcomes after about six weeks per unit, concluding by the end of that same
      school year. It does not mention any long-term follow-up past that point.
  r:
    met: false
    explanation: >-
      No independent replication is discussed; the trial stands as a single
      implementation.
    quote: >-
      "This is the first randomized experiment to directly test … a student incentive
      for an input activity against an output incentive …" (p. 2)
    analysis: >-
      For the 'Reproduced' requirement, we look for mention of an independent team
      replicating the exact intervention in a different setting. Although the paper
      references other technology-based or incentive-based experiments in the
      literature, it does not claim that a separate group repeated the same design.
  i:
    met: true
    explanation: >-
      The author was not the developer or owner of the KA Lite platform; the
      study was an external academic evaluation.
    quote: >-
      "Foundation for Learning Equality (FLE) developed the software platform
      (KA Lite)… additional funding from MFE allowed me to oversee this experiment.
      … This study was approved by IRB at UC San Diego and IFMR…" (p. 1–2,
      acknowledgments)
    analysis: >-
      'I - Independent Conduct' requires that the study team not be the original
      designers or proprietors of the intervention with a direct stake. The paper
      clarifies that FLE developed the KA Lite platform and that the author was
      affiliated with UC Riverside, not the developer or primary beneficiary.
      Thus, the independence requirement is met.
  p:
    met: true
    explanation: >-
      The authors pre-registered the study in the AEA RCT registry
      (AEARCTR-0000643) before conducting analyses.
    quote: >-
      "This study … is in the AEA registry as AEARCTR-0000643 … was registered while
      the trial was still ongoing." (p. 29)
    analysis: >-
      'Pre-Registered' means the study protocol was publicly registered prior to data
      collection. The paper states, "This study was approved by IRB at UC San Diego
      and IFMR, and is in the AEA registry as AEARCTR-0000643. … This study was
      registered while the trial was still ongoing and before any data was accessed or
      analyzed." This indicates a formal pre-registration on the AEA RCT registry,
      satisfying the P criterion.
---