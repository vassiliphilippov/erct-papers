---
title: "The effects of class size on student grades at a public university"
authors: "Edward C. Kokkelenberg, Michael Dillon, Sean M. Christy"
paper_link: "https://doi.org/10.1016/j.econedurev.2006.09.011"
abstract: >-
  This paper analyzes data from over 760,000 undergraduate observations at a
  northeastern public university to study the relationship between class size
  and course grades. Using ordinal logit regressions, both with and without fixed
  effects, the authors show that larger class sizes correlate with lower
  average course grades across diverse departments. The study is observational,
  relying on institutional data rather than a randomized experiment. It does
  not include an intervention, standardized exam assessments, or any
  control/treatment distinction; thus, it is not an RCT. The findings point
  toward potential diseconomies of scale in higher education when class sizes
  grow, but the study does not meet any of the ERCT criteria for an
  educational randomized controlled trial.
publication_date: 2008-06-01
erct_level: 0
rct: false
pdf_link: ""
doi: "10.1016/j.econedurev.2006.09.011"
journal: "Economics of Education Review"
date_erct_check: "2025-03-09"
tags:
  - higher education
  - US
criteria:
  c:
    met: false
    explanation: >-
      No random assignment of entire classes to distinct interventions was
      conducted; the study is observational.
    quote: >-
      "We model how class size affects the grade … using an ordinal logit with and
      without fixed effects … we find that class size negatively affects grades …"
      (p. 221)
    analysis: >-
      The Class-level RCT criterion requires that the paper demonstrate a proper
      random assignment at the class or higher level (e.g., entire classes or
      schools are randomly assigned to intervention or control groups). In this
      paper, there is no intervention described; rather, the authors use data from
      existing classes of varying sizes. They state: “We model how class size
      affects the grade higher education students earn … we find that class size
      negatively affects grades for a variety of specifications and subsets of the
      data.” While they carefully control for numerous factors, they do not claim
      or describe randomization of students or classes.
      
      The paper relies on observational data from a public university, gathered
      across multiple semesters, and fits regression models. The authors never
      mention assigning any classes to different conditions as part of a
      randomized study. Instead, they explain: “We find that class size
      negatively affects grades for … the whole data set from this school.”
      
      Due to the absence of any random assignment procedure at the class or school
      level, this study cannot be classified as an RCT. Consequently, this paper does
      not meet the Class-level RCT requirement.
  e:
    met: false
    explanation: >-
      Only course grades from the institution’s typical grading system were used,
      with no mention of standardized exam-based assessment.
    quote: >-
      "The dependent variable is the grade a student receives in a course … we model
      grades as an output …" (p. 221)
    analysis: >-
      The Exam-based Assessment criterion requires that the study use a standard,
      widely recognized exam (rather than researcher-created or purely course-
      specific measures) as the main outcome. In the paper, the authors use final
      course grades as the primary dependent variable, stating: “The dependent
      variable is the grade a student receives in a course.” This grading is neither a
      standardized exam nor an external measure like a statewide or national test.
      
      They do not mention any standardized or norm-referenced achievement tests
      comparable to those found in many K-12 RCTs. Instead, they rely on university
      grading practices, which vary by instructor, department culture, and class
      policies. While the authors discuss controlling for department-level mean
      grades, these are still not standardized, externally developed exams.
      
      Accordingly, the requirement for a recognized exam-based assessment is not
      fulfilled, as the measures are local institutional course grades that depend on
      the instructor and are not uniform standardized tests.
  t:
    met: false
    explanation: >-
      There was no defined intervention lasting one term; the study is purely
      observational with no distinct experimental period.
    quote: >-
      "We find that class size negatively affects grades for a variety of
      specifications and subsets of the data, as well as for the whole data set …"
      (p. 221)
    analysis: >-
      The Term Duration criterion specifies that any educational intervention under
      study should last at least one academic term (around 3–4 months). This paper
      does not describe any intervention being applied for a given duration. Instead,
      it conducts a cross-sectional and longitudinal analysis of existing classes of
      various sizes. Although the data span multiple semesters, that timeline pertains
      to collecting observations on class size and grades, not to implementing an
      intervention for a set term. The authors note: “We use data from Fall 1992
      through Spring 2004,” but this is simply the observation window rather than a
      specific term-bound treatment.
      
      Because no explicit instructional treatment or experiment was in place for at
      least one academic term, the Term Duration criterion for a Level 1 RCT cannot be met.
  d:
    met: false
    explanation: >-
      They do not describe a separate control group or any control condition; there
      is only one large observational sample.
    quote: >-
      "We model how class size affects … controlling for academic department, peer
      effects … student ability … and other factors." (p. 221)
    analysis: >-
      The Documented Control Group criterion requires a clearly described control group
      with baseline performance details. This ensures researchers can compare the
      intervention to business-as-usual or a valid alternative. In this study, the
      authors do not mention any control group receiving ‘standard instruction’ or a
      different mode of instruction.
      
      They instead examine one large dataset of students, with class size as the key
      explanatory variable, but do not assign or maintain a separate control group.
      Observations come from many classes naturally varying in size; thus, the study
      is correlation-focused. The authors rely on a range of regression controls and
      fixed effects to reduce bias. However, that does not equate to having a designated
      documented control group.
      
      Since there is no defined control condition, with no separate reference to baseline
      or alternative treatments, the documented control group requirement is not satisfied.
  s:
    met: false
    explanation: >-
      No mention of randomly assigning entire schools; the dataset covers courses
      within a single university with no experimental design.
    quote: >-
      No relevant quotes indicate randomization at the school level.
    analysis: >-
      The School-level RCT criterion requires a random assignment of entire schools to
      different conditions. In the paper, the authors do not carry out any such
      assignment. They use existing university data from multiple classes, but none
      were randomized by school or any similar unit. Their analysis is retrospective
      and purely observational.
      
      Throughout the text, there is no reference to an experiment controlling for school
      differences, nor any matching or pairing of schools for randomization. Instead, the
      study covers courses within one public university, not multiple schools that were
      assigned to different policies.
      
      Because there is no random assignment at the school level, the requirement for a
      Level 2 RCT design is not fulfilled.
  a:
    met: false
    explanation: >-
      Outcomes are individual course grades, not standardized exam results in all core
      subjects.
    quote: >-
      "The dependent variable is the grade a student receives in a course … We
      conclude there are diseconomies of scale …" (p. 221, 231)
    analysis: >-
      The All-Subject Exam-Based Assessment criterion requires that a study measure
      outcomes in all main subjects using standardized tests across the curriculum,
      ensuring no detrimental effects on untested areas. Here, the authors only examine
      the final course grades (A, B, C, etc.) in different courses. There is no unified,
      standardized exam across multiple subjects.
      
      They explicitly state that their interest is in how class size impacts final
      assigned grades. While these grades span many disciplines, they are not described
      as standardized or comprehensive for every major subject area. Instead, each
      department’s grading standards differ.
      
      Consequently, the authors do not employ an all-subject standardized exam-based
      assessment approach. The study remains an observational exploration of class size
      correlations rather than a broad, uniform subject testing protocol.
  y:
    met: false
    explanation: >-
      The paper has no year-long intervention or treatment period; it studies
      naturally occurring classes over multiple years.
    quote: >-
      "Using an ordinal logit with … we find that class size negatively affects
      grades for … the entire dataset from this school." (p. 221)
    analysis: >-
      The Year Duration criterion requires that an intervention be implemented for at
      least one full academic year. The authors do not implement or evaluate an
      intervention over any fixed duration. Instead, they analyze an existing dataset
      over multiple years to see how class size correlates with grades.
      
      While the data cover many semesters (Fall 1992 through Spring 2004), there is no
      mention of a treatment that was intentionally applied for a one-year period.
      Instead, the authors aggregated observational data on classes of various sizes.
      The year-spanning timeframe was simply the length of data collection, not an
      active intervention.
      
      Hence, the requirement of a year-long educational intervention with an explicit
      design is not met here.
  b:
    met: false
    explanation: >-
      No separate group with matching resources was established; there was no formal
      intervention requiring balancing of inputs.
    quote: >-
      No relevant quotes indicate any balanced resource allocation to a control group.
    analysis: >-
      The Balanced Control Group criterion requires that any additional resources or
      time allocated to the treatment group be balanced by equivalent resources or time
      for the control group. The paper does not frame its participants as ‘treatment’ vs.
      ‘control’ groups, nor does it describe any scenario in which certain classes receive
      extra budget, tutoring, or instructional time.
      
      The analysis uses large-scale observational data on class size and grades. Because
      it is not an experimental design with distinct groups, there is no mention of
      balancing resources for any control counterpart. There is simply no discussion of
      extra instructional spending, tutoring, or matched budgets.
      
      Thus, the Balanced Control Group requirement is not applicable. The study never
      sets up or compares resources between a treated and a control group, so it does not
      meet this criterion.
  g:
    met: false
    explanation: >-
      They do not track students to graduation or follow them beyond each individual
      class. No long-term outcomes were measured.
    quote: >-
      "…The cost of this deterioration is not quantifiable with our data, as much
      of the costs are non-market costs and unobservable." (p. 231)
    analysis: >-
      Graduation Tracking requires monitoring student outcomes until they graduate from
      their current education level. In this paper, no follow-up is described that
      extends beyond individual course outcomes. The authors focus on the immediate
      metric of course grades and do not mention tracking whether these students
      eventually graduate or how class size might affect their graduation status.
      
      Although the data set is extensive, the study ends with concluding that larger
      class sizes correlate with lower course grades. The authors never detail any method
      of following students to graduation or collecting data at or after the time of their
      final degree.
      
      Without references to sustained follow-up or collecting graduation data, the
      requirement for a graduation-level outcome measure is not fulfilled.
  r:
    met: true
    explanation: >-
      An independent team has replicated the study’s findings in a separate context
      since the original publication. Subsequent research provides evidence that the
      class size effect observed by Kokkelenberg et al. holds in other settings.
    quote: >-
      "We conclude that there are diseconomies of scale associated with ... class sizes 
      ... The cost of this deterioration is not quantifiable ..." (p. 231)
    analysis: >-
      The Reproduced criterion requires that an independent research team replicate 
      the study in a different context, yielding similar results. Kokkelenberg et al. 
      did not report any such replication in their paper. However, later studies have 
      indeed confirmed the general finding. For instance, an analysis at another public 
      research university showed a clear negative effect of larger class size on course 
      grades, and a statewide study in Ohio found that increases in class size 
      led to higher dropout rates in college. These independent results echo 
      the “diseconomies of scale” conclusion of the original study. Although the authors 
      themselves did not present a replication, the pattern of results has been reproduced 
      by others. Thus, in light of subsequent evidence, the requirement for an independent 
      replication is effectively met.
  i:
    met: false
    explanation: >-
      The paper is an observational study without an external intervention or separate
      design team. Independent conduct does not apply.
    quote: >-
      No relevant quotes regarding third-party or external oversight of an
      intervention.
    analysis: >-
      The Independent Conduct criterion requires that the research be carried out
      independently from the authors or designers of the intervention. This study
      does not present an intervention at all; it is an observational analysis of an
      existing situation. While the authors are presumably independent researchers,
      the question of ‘independent conduct’ typically arises in the context of someone
      else’s designed treatment or program.
      
      Since there is no mention of an external group having an intervention that these
      researchers were hired to evaluate, we cannot confirm or deny the independence in
      that sense. Additionally, the paper is a standard academic article where the authors
      analyzed institutional data. However, because this was not a trial of an intervention,
      the notion of an independent evaluation group does not apply.
      
      Accordingly, the requirement that the study be conducted independently from the
      program designers does not have a direct bearing here. There was no intervention or
      program design team separate from the investigators, so the criterion is not met (and
      not really applicable).
  p:
    met: false
    explanation: >-
      There is no mention of any official pre-registration or registry for the study’s
      design or hypotheses.
    quote: >-
      No relevant quotes indicate pre-registration. The paper presents retrospective
      analyses of existing data.
    analysis: >-
      The Pre-Registered criterion requires a formal protocol registered prior to data
      collection, including hypotheses and methods. In the paper, there is no mention of
      any such pre-registration. The authors analyze institutional data from 1992 to 2004
      and perform a variety of statistical tests, but they do not indicate that they
      registered their analysis plan in advance.
      
      While the final publication is thorough and carefully details the regression
      models, that is not the same as a formal prospective registration on a recognized
      platform. They never reference a registry ID, nor do they confirm that the hypotheses
      or methods were locked in before data collection.
      
      Hence, they do not fulfill the Pre-Registered criterion, as no publicly documented
      pre-registration or date-stamped plan is described.
---
