---
title: The effects of computer-assisted adaptive instruction and elaborated feedback on
  learning outcomes. A randomized control trial
authors: Kaat Iterbeke, Kristof De Witte, Wouter Schelfhout
paper_link: "https://doi.org/10.1016/j.chb.2020.106666"
abstract: >-
  Using a computer-based learning environment, the present paper studied the effects
  of adaptive instruction and elaborated feedback on the learning outcomes of secondary
  school students in a financial education program. We randomly assigned schools to
  four conditions on a crossing of two factors: the type of instruction (uniform or
  adaptive) and feedback (verification or elaborated). A total of 1,177 students in 32
  schools completed the program in ability groups in the classroom. The results showed
  that the program, on average, enhanced the financial knowledge of students by almost
  half of a standard deviation. No significant changes in students’ financial behavior
  were found. Despite the promise of adaptive practices to address the individual needs
  of students, we observed no additional learning gains associated with adaptive
  instruction and elaborated feedback. A marginally significant heterogeneous effect for
  gender was reported, where girls were negatively affected by adaptive instruction.
  Moreover, despite our sample included more students from a favorable socioeconomic
  status, the adaptive practices seemed to lower the motivation level. Hence, while no
  information on the time spent on the instruction and feedback was retrieved, the
  latter finding suggested that the practices may have been perceived as burdensome by
  students, thereby rendering them ineffective.
publication_date: 2020-12-13
erct_level: 0
rct: true
pdf_link: ""
doi: "10.1016/j.chb.2020.106666"
journal: "Computers in Human Behavior"
date_erct_check: "2025-03-09"
tags:
  - K12
  - EU
  - online homework
  - EdTech website
  - digital assessment
criteria:
  c:
    met: true
    explanation: >-
      They randomized entire schools, which is stronger than class-level
      randomization.
    quote: >-
      “Randomization was conducted at the school level in order to avoid
      contamination effects.” (p. 4)
    analysis: >-
      Quotes:

      1) “We randomly assigned schools to four conditions on a crossing of two
      factors: the type of instruction (uniform or adaptive) and feedback
      (verification or elaborated).” (p. 2)

      2) “Randomization was conducted at the school level in order to avoid
      contamination effects.” (p. 4)
      3) “In total, 32 schools ... participated in the final sample.” (p. 8 and
      Table III)

      Analysis:

      (1) The paper clearly states that the unit of randomization was the school.
      Under the ERCT Standard, school-level randomization is considered stronger than
      class-level randomization, and therefore it automatically satisfies the
      requirement for class-level RCT. The authors wrote, “We randomly assigned
      schools to four conditions…,” indicating an entire school (rather than individual
      students or only certain classes) was the randomized unit.

      (2) Since randomization at the school level generally eliminates the possibility
      that some classes within the same school might receive the same intervention
      (risking contamination), it also meets or exceeds the requirement of randomizing
      entire classes. If this were strictly a within-class randomization, we would be
      worried about contamination.

      (3) The study’s explicit mention of the desire to “avoid contamination effects”
      is precisely the rationale behind not randomizing at the student level within the
      same classroom. Hence, the stronger school-level RCT satisfies the ‘C - Class-level
      RCT’ criterion.
  e:
    met: false
    explanation: >-
      They used a mix of custom questions (some drawn from prior literature) and did not 
      employ a widely recognized standardized exam.
    quote: >-
      "The pre-treatment test was designed as a computer-aided multiple-choice test. 
      The test included several questions on students’ demographics and eight questions 
      that referred directly to the material and measured students’ financial 
      proficiency." (p. 5)
    analysis: >-
      Quotes:

      1) “We randomly assigned schools to four conditions ... and designed four 
      lectures of 50 minutes in the form of a computer-assisted learning path.” (pp. 3–4)

      2) “The pre-treatment test was designed as a computer-aided multiple-choice 
      test ... The test included several questions on students’ demographics and 
      eight questions that referred directly to the material...” (p. 5)

      3) “Two questions for the latter three financial concepts were taken from 
      Lusardi and Mitchell (2011) ... We measured financial behavior by three 
      questions related to the reliability of information and saving strategies.” 
      (p. 6)
      (The post-treatment test included similar questions as the pre-test, and no 
      official standardized exam (state or national) was used.)
      
      Analysis:

      (1) The ERCT Standard requires an exam-based assessment that is **standardized** 
      and not created solely by the researchers for the purpose of the study. In this 
      paper, the authors used a set of multiple-choice items, partly drawn from well-known 
      financial literacy surveys (e.g., Lusardi & Mitchell), but there is no clear 
      statement that these items amount to a recognized, official standardized exam.

      (2) The paper notes that the tests contained custom questions measuring financial 
      literacy in alignment with the program content (topics like saving, risk, inflation, 
      interest, etc.). Although they reference some previously published questions, the 
      overall instrument is a researcher-assembled mix, not a standard test used in 
      large-scale assessments.

      (3) The authors do not claim to have used any state-wide or national standardized 
      test. Therefore, the **Exam-based Assessment** criterion is not satisfied.
  t:
    met: false
    explanation: >-
      They delivered four sessions (about three hours total), which is shorter than one
      academic term.
    quote: >-
      “The learning material was designed as four lectures of 50 minutes in the form
      of a computer-assisted learning path.” (p. 5)
    analysis: >-
      Quotes:

      1) “The learning material was designed as four lectures of 50 minutes in the
      form of a computer-assisted learning path.” (p. 5)

      2) “Hence, students received about 200 minutes (4 x 50) of instruction total,
      delivered during regular class hours.” (p. 5, paraphrased from context)

      3) “Using the computer-based program, we studied the short-term effect on a
      post-test administered at the end of these four lectures.” (p. 6)

      Analysis:

      (1) Under the ERCT Standard, a study must run for at least a full academic term
      (often ~3–4 months) to meet the T (Term Duration) requirement. In this paper, the
      intervention took place during four class sessions (4 x 50 minutes = roughly 3.3
      hours total).

      (2) While the paper does indicate a follow-up test “approximately four weeks after
      the lectures” as homework, the main intervention spanned only these short sessions.
      This does not align with an entire semester or term-based intervention.

      (3) Given that the study specifically highlights only a few hours of in-class program
      usage, it is significantly shorter than the minimum term duration. Thus, T is not met.
  d:
    met: true
    explanation: >-
      The study documents the control group’s characteristics (demographics and baseline 
      scores) in detail, with separate columns for the control group in Table III.
    quote: >-
      "Table III presents the school and student characteristics for the final sample 
      involving 1,177 students, 94 classes, and 32 schools... **Student background 
      characteristics, as presented in panel B, show that, on average, 50 percent of 
      students were female, 88 percent spoke Dutch (the official language) at home, and 
      students were 13 and half years old, on average.**" (pp. 8–9)
    analysis: >-
      Quotes:

      1) “A total of 1,177 students in 32 schools completed the program ... We randomly 
      assigned schools to four conditions on a crossing of two factors...” (p. 2)

      2) “In the control condition, students did not receive the financial education 
      program. ... Teachers in the control schools obtained the material after their 
      students took the pre- and first post-treatment test as an incentive...” (p. 5)

      3) “Table III presents the school and student characteristics for the final sample 
      involving 1,177 students, 94 classes, and 32 schools, which were randomly assigned 
      to one of the conditions.” (p. 8)

      4) “Panel B. Background characteristics … On average, 50 percent of students were 
      female, 88 percent spoke Dutch at home, etc. … Panel C. Pre financial scores.” (Table III)
      
      Analysis:

      (1) Criterion D requires that the control group’s makeup and baseline data be clearly 
      described. In this study, the authors provide extensive baseline statistics for all 
      groups in **Table III**, including a dedicated column for the control group.

      (2) The authors explicitly state that the control group “did not receive the financial 
      education program” (i.e. business-as-usual), and they offer the intervention materials 
      to those teachers only after the study, indicating no special treatment was given during 
      the study period. 

      (3) Table III and its narrative description detail student demographics (gender, language, 
      etc.) and pre-test scores (financial knowledge/behavior) for the control vs. treatment groups. 
      This level of detail allows readers to confirm the control group was comparable at baseline. 
      Therefore, the **Documented Control Group** criterion is met.
  s:
    met: true
    explanation: >-
      Schools were the unit of randomization, fulfilling the requirement for S.
    quote: >-
      “Randomization was conducted at the school level in order to avoid contamination
      effects.” (p. 4)
    analysis: >-
      Quotes:

      1) “Randomization was conducted at the school level in order to avoid
      contamination effects.” (p. 4)

      2) “We randomly assigned schools to four conditions on a crossing of two factors:
      the type of instruction (uniform or adaptive) and feedback (verification or
      elaborated).” (p. 2)

      3) “32 schools completed the program ... 9 schools in the control, 5 in
      uniform-EF, 10 in adaptive-EF, 8 in adaptive-VF.” (Table III, p. 8)

      Analysis:

      (1) The S criterion (School-level RCT) requires that entire schools, not just classes or
      students within a school, be randomly assigned. The quotes confirm that the
      randomization unit is indeed the school.

      (2) Because the authors explicitly mention “we randomly assigned schools” and
      emphasize that this prevented contamination, it demonstrates the design meets
      the requirement for S. This approach is typically more logistically demanding,
      but it is considered stronger in capturing real-school effects.

      (3) Consequently, the study clearly meets the standard for a school-level RCT.
  a:
    met: false
    explanation: >-
      The study only measured outcomes in financial literacy (knowledge and behavior); it did 
      not assess performance in other core subjects (e.g. math, language), as required for the 
      "All-subject exams" criterion.
    quote: >-
      "We assessed financial knowledge by five questions covering the calculation of monthly 
      savings, risks and rewards, rates of return, interest, and inflation. ... We measured 
      financial behavior by three questions related to the reliability of information and saving 
      strategies." (pp. 5–6)
    analysis: >-
      Quotes:

      1) “Financial literacy can be decomposed into financial knowledge and financial behavior. 
      We assessed financial knowledge by five questions ... We measured financial behavior by 
      three questions...” (pp. 5–6)

      2) “We ... studied the effects on the learning outcomes of secondary school students in a 
      financial education program.” (p. 2)

      3) “The results showed that the program, on average, enhanced the financial knowledge of 
      students by almost half of a standard deviation.” (p. 2)
      
      Analysis:

      (1) All-subject Exam-based Assessment requires that the study measure learning outcomes 
      in all major subjects (or justify a focus on a specialized domain). Here, the outcomes are 
      specific to financial education only (a specialized subject matter).

      (2) The authors make no mention of testing students in general subjects like mathematics, 
      reading, or science. All outcome measures (financial knowledge and financial behavior) are 
      within the single domain of financial literacy.

      (3) Because the study’s assessments are narrowly focused on one subject area and it doesn’t 
      evaluate broad academic achievement across the curriculum, it fails to meet the “All-subject 
      exams” criterion.
  y:
    met: false
    explanation: >-
      Their intervention was only four class sessions plus a 4-week follow-up, nowhere near a
      full academic year.
    quote: >-
      “The learning material was designed as four lectures of 50 minutes ... approximately
      four weeks after, a second post-treatment test.” (pp. 5–6)
    analysis: >-
      Quotes:

      1) “The learning material was designed as four lectures of 50 minutes.”
      (p. 5)

      2) “Approximately four weeks after the lectures, students in the treatment
      schools completed the second post-treatment test as a homework assignment.”
      (p. 6)

      Analysis:

      (1) The Y criterion requires the intervention to last at least one full academic
      year, or the study to track participants for that duration. Here, the authors’
      main program spanned a few weeks at most, plus a short follow-up.

      (2) The total formal instruction time was only four 50-minute sessions, not an
      entire year. Although the second post-test was a month later, that does not
      equate to a year-long intervention.

      (3) As a result, the study does not meet the requirement for Y, which demands a
      full academic year of intervention.
  b:
    met: false
    explanation: >-
      The control group received no equivalent budget or instructional time to match the
      specialized sessions of the treatment group.
    quote: >-
      “In the control condition, students did not receive the financial education program ...
      Teachers in the control schools obtained the material after.” (p. 5)
    analysis: >-
      Quotes:

      1) “In the experimental condition, student pairs received an adaptive or uniform
      learning path on financial literacy ... whereas the control condition did not
      receive the financial education program.” (p. 5)

      2) “Students in the control condition merely completed the pre- and post-tests,
      with no special resources or additional time.” (p. 5)

      3) “Teachers in the control schools obtained the material only after their
      students took the pre- and first post-treatment test.” (p. 5)

      Analysis:

      (1) The Balanced Control Group criterion requires that if the treatment group receives
      extra resources or additional instructional time, the control group must also receive
      equivalent resources/time to isolate the effect of the specific intervention. Here,
      the experimental group spent dedicated class sessions working on the financial
      literacy modules and had a specialized computer-based program.

      (2) The control group did not receive any parallel or compensatory time or budget.
      They were effectively kept on “business as usual” with no additional resources.
      This suggests a resource/time imbalance.

      (3) As a result, they do not meet B. The difference in instruction time and materials is
      not offset with a matching resource for the control.
  g:
    met: false
    explanation: >-
      They measured immediate and 4-week follow-up effects only, with no tracking until
      graduation.
    quote: >-
      “Approximately four weeks after the lectures, students completed the second
      post-treatment test as a homework assignment.” (p. 6)
    analysis: >-
      Quotes:
      1) “We measured the short-term impact of the financial education program ... and
      a second post-treatment test as a homework assignment about four weeks after
      the lectures.” (p. 6)

      2) “The results showed the improvement in financial knowledge to be retained in the
      short run, though no mention is made of longer tracking.” (pp. 6–7)

      Analysis:

      (1) G (Graduation Tracking) requires the study to follow up on students until they
      graduate from that school level to see if the intervention’s effect persists. Here,
      participants were observed for only a brief period: one immediate post-test and one
      follow-up about a month later.

      (2) The paper does not describe any data collection continuing through the end of the
      relevant school grade, let alone graduation from secondary education.

      (3) Consequently, the criterion for a sustained follow-up through graduation is not
      satisfied.
  r:
    met: false
    explanation: >-
      The study has not been independently replicated by a different research team (no such 
      replication is reported by the authors).
    quote: >-
      (No independent replication of this intervention is mentioned in the paper.)
    analysis: >-
      Analysis:

      (1) To satisfy R, a separate research team should have replicated the same experiment in 
      a different setting. There is no indication anywhere in the article that an external team 
      repeated this study.

      (2) The authors cite other financial education studies for context, but these are **not** 
      replications of this specific intervention and design.

      (3) Thus, the criterion **Reproduced** is not met — the results have not been confirmed by 
      an independent replication study.
  i:
    met: false
    explanation: >-
      The authors designed and evaluated the intervention themselves; no independent
      research or external evaluator was involved in running the study.
    quote: >-
      “The learning material was designed as four lectures of 50 minutes in the form of a
      computer-assisted learning path.” (p. 5)
    analysis: >-
      Quotes:

      1) “CRediT author statement: ... Conceptualization, Methodology, Formal analysis,
      Investigation, Writing...” (front matter)

      2) “The learning material was designed as four lectures of 50 minutes ... We took
      care in designing our study to prevent potentially confounding influences.” (p. 15)

      3) “We are grateful to ... for research assistance. ... We thank seminar
      participants ... for valuable suggestions.” (p. 20)

      Analysis:

      (1) Under I (Independent Conduct), the study team implementing and analyzing the
      intervention should be independent from the developers/designers of the
      intervention. In this paper, the same authors appear to have designed the program
      (the learning path, random assignment process) and carried out the evaluation.

      (2) The text does not suggest that an external, third-party evaluator performed the
      trial. Instead, the authors wrote the learning modules themselves, administered
      them, and analyzed the results.

      (3) This does not fulfill the independence requirement because the same research
      group that created the content also tested it. Hence, I is not met.
  p:
    met: false
    explanation: >-
      The study was registered after the intervention and data collection were completed, 
      which does not satisfy the criterion for pre-registering the protocol before data collection.
    quote: >-
      "Initial registration date: September 23, 2019"
    analysis: >-
      Quotes:

      1) "Intervention Start Date: September 17, 2018"

      2) "Intervention End Date: January 31, 2019"

      3) "Initial registration date: September 23, 2019"
      
      Analysis:

      (1) The ERCT Standard requires that the study's protocol be publicly registered before data collection begins. 
      In this case, the intervention and data collection were completed by January 31, 2019, but the study was 
      registered on September 23, 2019.

      (2) Therefore, the criterion for a pre-registered protocol is not met.
---
