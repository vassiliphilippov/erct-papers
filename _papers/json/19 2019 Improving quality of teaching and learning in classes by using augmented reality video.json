{
  "title": "Improving quality of teaching and learning in classes by using augmented reality video",
  "authors": "Joanne Yip, Sze-Ham Wong, Kit-Lun Yick, Kannass Chan, Ka-Hing Wong",
  "url": "https://doi.org/10.1016/j.compedu.2018.09.014",
  "slug": "yip-et-al-2018-ar-video",
  "abstract": "This study compares a traditional handout versus an augmented reality (AR) video approach to teaching threading and knitting concepts in textile-related courses. The authors randomly split students into two groups (handout vs. AR video) and measured learning outcomes via short tests, threading performance, time-on-task, and questionnaire responses. Results suggest that AR-based instruction increases students’ understanding of complex 3D processes and reduces the time required to learn certain tasks. The paper describes the randomized assignment, the educational context, test details, and data analysis of pre- and post-tests, concluding that AR video use is a promising instructional tool for textile and clothing students.",
  "publication_date": "2018-09-23",
  "erct_level": 0,
  "rct": true,
  "criteria": {
    "c": {
      "analysis": "The paper explicitly states that a randomized controlled trial (RCT) was run, with students placed into two groups and different tutorial sessions. One group received a handout (control) and the other used AR videos (intervention). Quotes from the paper include: “To reduce selection bias and obtain more accurate results, a randomized controlled trial (RCT) was run. Study participants were randomly allocated to two different groups...” (Section 2.2) and “All participants were blind to the study in that they did not have information about the learning tool until they started their tutorial class.” (Section 2.3.1). The paper also explains that “...all students were randomly allocated into different Intimate Textiles and Accessories classes by the PolyU computer system.” (Section 2.3.2).\n\nThese statements demonstrate that randomization was performed at the tutorial-class level rather than assigning individual students within the same classroom to different conditions. In other words, each tutorial class as a whole was allocated to either the AR-video condition or the handout condition. This cluster-level approach (by class) meets the requirement for Criterion C, which is that entire classes (or a stronger school-level approach) are assigned to treatment or control.\n\nNo evidence in the paper suggests that they randomized individual students within a single class, and there is no indication that the intervention is solely for individualized tutoring or personal teaching. Hence, the study meets the Class-level RCT criterion because they used whole-class randomization (albeit across different tutorial sessions). Therefore, Criterion C is satisfied.",
      "met": true,
      "explanation": "They clearly randomized at the class (tutorial session) level, satisfying the requirement for Class-level RCT.",
      "quote": "“...a randomized controlled trial (RCT) was run. Study participants were randomly allocated... all students were randomly allocated into different classes by the PolyU computer system.”"
    },
    "e": {
      "analysis": "This criterion requires that the outcomes be measured using a well-known, standardized exam. However, the paper describes using custom-made tests: “The test comprised two sections… a score of 16 was given if the needle movement steps were arranged correctly…” (Section 2.3.2) and “To evaluate the learning efficiency… a pre-test was carried out before the students received the handout or downloaded the AR videos… The time required for each student to finish the task was recorded…” (Section 2.4.2.1). These tests appear to be tailored specifically to measure students’ ability to thread or operate textile machinery and understand needle movements.\n\nThere is no mention of an officially recognized standardized assessment such as a state-wide exam, a national standardized test, or an externally validated measure with known psychometric properties. Instead, the researchers constructed their own short quizzes and performance tasks to evaluate threading and knitting knowledge. While these custom tools may be valid for local instructional purposes, they do not fulfill the criterion of a standard exam-based assessment recognized beyond the immediate study context.\n\nBecause the authors rely on researcher-designed tests and practical skill measures (time to complete threading, correct steps, etc.) rather than a widely recognized standardized exam, the requirement of using exam-based assessments (Criterion E) is not met.",
      "met": false,
      "explanation": "They used custom-created quizzes and performance metrics instead of any external standardized exam.",
      "quote": "“A simple test on three main types of knitting needles… The test comprised two sections… a score of 16 was given… The students were required to thread a flat sewing machine… the time required for each student to finish the task was recorded.” (Sections 2.3–2.4)"
    },
    "t": {
      "analysis": "To satisfy Criterion T, the intervention should span at least an entire academic term (approximately 3–4 months). In this paper, the authors describe a relatively brief set of learning trials: “A simple test… was given on 15 September 2017… Another trial on basic terminology and understanding of the threading process was designed… from 26 to 29 September 2017.” (Sections 2.3, 2.4). This short timescale does not amount to a full semester or term.\n\nThe paper makes no mention of a sustained implementation over multiple months. Instead, the reported timeline suggests that the AR intervention and handout-based intervention were each introduced and tested in a short timeframe, covering only a single session or a few workshop days. This compressed schedule is typical for a small-scale instructional study but does not align with the requirement that the intervention run for one academic term.\n\nHence, because the intervention and data collection appear to have occurred within days or weeks rather than an entire term, this criterion is not met.",
      "met": false,
      "explanation": "The study took place over brief sessions in September rather than covering a full academic term of at least several months.",
      "quote": "“A simple test on… was given on 15 September 2017… The threading task in sewing workshops… from 26 to 29 September 2017.” (Sections 2.3–2.4)"
    },
    "d": {
      "analysis": "Criterion D requires a clearly documented control group with baseline characteristics and conditions. This paper contrasts Group A (handout) with Group B (AR videos). They provide the size of each group: “Forty-six freshmen registered… 27 in Group A and 19 in Group B” (Section 2.4.1). They also give some demographic details: “All participants were… 4 males and 42 females” (Section 2.4.1), plus baseline knowledge or skill was assessed via a pre-test. For example, “Regardless of their allocated group, all students had to finish the task [threading] but were not given a time limit… Their score… was recorded… The aim was to assess the learning outcomes of both groups…” (Sections 2.3.2, 2.4.2).\n\nThey similarly document that the control group used only a written handout, describing their experiences, while the AR group had the app-based approach. They also show the pre-test and post-test comparisons, clarifying that the control group spent about the same amount of time in the workshop but had no AR videos. The authors highlight the control group’s results for each measure (time to thread, final test scores, etc.) and mention that the control group needed more time and found the process more difficult.\n\nOverall, the authors do identify the control group’s composition, pre-test performance, and the conditions they received (no AR technology). This level of detail satisfies Criterion D’s requirement for a documented control group, even though it is not as extensive as large-scale demographic tables might be. They do report group sizes, pre-test scores, and confirm that the control group simply used a standard handout, facilitating clarity on what the control group actually experienced.",
      "met": true,
      "explanation": "They provide basic demographic info, pre- and post-test scores, and clearly note that the control group used only a handout with no AR resources.",
      "quote": "“...46 freshmen… 27 were placed in Group A (handouts), 19 in Group B (AR videos). All participants were… 4 males and 42 females… a pre-test was carried out before the students received the handout or downloaded the AR videos…” (Sections 2.4.1–2.4.2)"
    },
    "s": {
      "analysis": "This Level 2 criterion (S) requires randomization at the school level, meaning entire schools (not just classes) are assigned to intervention or control. The paper focuses on students at one institution (The Hong Kong Polytechnic University) and describes random assignment of entire tutorial classes or sessions, but not entire schools. Quotes reference “...all students were randomly allocated into different Intimate Textiles and Accessories classes by the PolyU computer system...” but do not mention multiple schools.\n\nSince the study took place in a single university department using tutorial-class groupings rather than an inter-school design, it does not meet the threshold for school-level RCT. The standard for S is typically relevant to K–12 or multi-school educational contexts, which is not the case here.\n\nHence, while they do have a cluster randomization approach at the level of tutorial classes, they are not randomizing entire schools. This means Criterion S is not satisfied.",
      "met": false,
      "explanation": "They randomized classes within one university department, not entire schools.",
      "quote": "No quotes indicate multi-school assignment; they mention only that students were randomly allocated into tutorial classes."
    },
    "a": {
      "analysis": "Criterion A (AllExams) requires measuring outcomes in all main academic subjects (or a justified subset if it is vocational) using standard exams, to check for unintended negative effects in other domains. The paper focuses exclusively on tasks related to knitting needles, threading, and sewing machine operations within textiles/clothing courses. There is no indication that the authors assessed learning in other subject areas (such as mathematics, writing skills, or other core disciplines). Instead, the study measures only the outcome of improved performance in operating textile machinery.\n\nWhile the approach is understandable for a specialized course in textiles, it does not meet the requirement for a comprehensive, all-subject exam-based assessment. The authors never purport to measure broader learning or other academic subjects. Therefore, Criterion A is not met.\n\nIt is worth noting that the authors primarily aimed to see if AR-based instruction improved a specific skill (threading and needle comprehension). This narrower scope is valid for their goals but does not fulfill “AllExams.”",
      "met": false,
      "explanation": "They evaluated only sewing/knitting performance and knowledge, with no mention of measuring every main subject area via standardized exams.",
      "quote": "“...the study focused on the evaluation of an AR application in education… the innovation… particularly for learning a complicated task/concept, i.e., threading.” (Section 5)"
    },
    "y": {
      "analysis": "Criterion Y requires that the intervention last for at least one full academic year. The paper describes a short study spanning only a few weeks in September. Specifically, “...the simple test on knitting needles was given on 15 September...” followed by a threading task at the end of the same month. There is no mention of continuing the intervention for an entire year.\n\nBecause the study only covered a brief period (likely days or weeks), it does not fulfill the year-long requirement. The authors mention no extended follow-up or multiple months of AR usage. Therefore, Y is not met.\n\nShort classroom experiments are common in educational research but do not meet the stricter demands of a year-long intervention.",
      "met": false,
      "explanation": "The entire intervention and data collection took place over a short timeframe, not spanning a full academic year.",
      "quote": "“A simple test… 15 September… Another trial… 26 to 29 September… The time required for each student… was recorded.” (Sections 2.3–2.4)"
    },
    "b": {
      "analysis": "To meet Criterion B, if the treatment group receives extra resources (budget, technology, or instructional time), then the control group should receive an equivalent resource injection to rule out mere resource differences. The authors describe that the intervention group used a specially developed AR mobile application, while the control group only had a handout. The AR group presumably had more technological resources (an app, phone usage, special content). There is no mention of providing the control group with any comparable resource or time balance.\n\nThe paper does not describe an attempt to equate total budgets or instructional time given to each group, e.g., the control group receiving some parallel digital resource or extra budget. The authors simply provided Group B with an AR app and Group A with a typical printed handout. That mismatch is precisely what B warns about: it can be unclear if the AR effect is due to novelty or additional resources. While this design can be valid for research, it does not satisfy the Balanced Control Group requirement.\n\nHence, B is not met because there is no equivalently augmented resource for the control group to isolate the specific effect of AR from extra technology/time/funding factors.",
      "met": false,
      "explanation": "The intervention group had AR technology, but the control group only had a handout and no equivalently increased resources or budget.",
      "quote": "“Group A (handout)… Group B (AR video)… no mention of matching resources or budget for the control group.” (Sections 2.4.2–2.4.3)"
    },
    "g": {
      "analysis": "Criterion G (Graduation Tracking) calls for following students until they graduate from that school level, ensuring a long-term outcome measure. This paper reports only immediate effects on test performance and skill demonstration after a short learning intervention. For example, “When the students finished threading, their time spent… and their score were recorded.” (Section 2.4.2.2).\n\nThe authors do not describe any follow-up or tracking beyond that immediate post-intervention test. They do not mention seeing if these students eventually graduated or if the gains were retained. Therefore, the requirement to track participants through graduation is not met.\n\nBecause the data collection ended soon after the short intervention, G is not satisfied.",
      "met": false,
      "explanation": "They gathered only short-term data from immediate post-tests, with no extended tracking through graduation.",
      "quote": "“Another trial on basic terminology and understanding… The results obtained in the simple test… were then assessed… [no mention of following them to graduation].” (Sections 2.3–2.4)"
    },
    "r": {
      "analysis": "Criterion R requires that the study be reproduced by an independent team in a different context, demonstrating replication. The paper does not mention any independent replication attempts or other published studies implementing the same AR approach with a new population by a separate research group. They only present their own single study design at The Hong Kong Polytechnic University.\n\nNo references describe follow-up replications or expansions by others. Thus, R is not met.\n\nWhile the authors mention future directions, the text does not indicate that any external group has repeated the same method independently. Therefore, the requirement for an independently reproduced study is not satisfied.",
      "met": false,
      "explanation": "No independent replication is reported or cited; they only describe their single study in one institution.",
      "quote": "The paper does not mention any separate or replicated study by another research team."
    },
    "i": {
      "analysis": "Criterion I (Independent Conduct) requires that the study be conducted by a team independent from the intervention’s designers. Here, the authors themselves created the AR app called “ITC VR AR” as part of their program: “To apply AR to the learning environment, a mobile application (app) called ITC VR AR was developed by the Institute of Textiles and Clothing (ITC)…” (Section 2.2). The same authors—particularly from the Institute of Textiles and Clothing—then tested the efficacy of this newly developed AR tool.\n\nThe text does not explicitly mention an external or neutral evaluator collecting data or performing the analysis. Instead, it appears that the same institution developed the AR app and measured its effectiveness, which raises the possibility of partial or unintentional bias in favor of their own intervention. There is no statement that a separate, independent organization ran the evaluation.\n\nBecause the authors were directly responsible for both the intervention design (the AR app) and the entire research process, the study does not satisfy the requirement that it be independently conducted by a team unaffiliated with the intervention. Hence, I is not met.",
      "met": false,
      "explanation": "The same group that designed the AR app also conducted the research, with no independent evaluation team.",
      "quote": "“A mobile application (app) called ITC VR AR was developed by the Institute of Textiles and Clothing… The aim… to determine whether AR videos can improve teaching.” (Sections 2.2, 2.5)"
    },
    "p": {
      "analysis": "Criterion P (Pre-Registered) requires that the study protocol, hypotheses, and analysis plan be published or posted in a recognized registry prior to data collection. The paper does not reference any pre-registration (e.g., a date, a registry ID, or a mention of prospective registration). Instead, it simply describes the design, method, and results as an original study.\n\nNo statements indicate that the authors posted a formal plan ahead of time, nor do they cite OSF, ClinicalTrials.gov, or any similar platform. Thus, there is no evidence of pre-registration, and P is not met.\n\nWhile this does not invalidate the study’s findings, it means they did not complete the pre-registration process that ensures transparency around planned analyses.",
      "met": false,
      "explanation": "They did not mention registering their protocol before data collection; no public registry link or ID is cited.",
      "quote": null
    }
  }
}
