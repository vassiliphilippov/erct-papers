{
  "title": "Leveraging Technology to Engage Parents at Scale: Evidence from a Randomized Controlled Trial",
  "authors": "Peter Bergman, Eric W. Chan",
  "url": "https://ssrn.com/abstract=2989472",
  "slug": "bergman-chan-2017-leveraging-technology",
  "abstract": "We partner text-messaging technology with school information systems to automate the gathering and provision of information to parents at scale. In a field experiment across 22 middle and high schools, we used this technology to send automated text-message alerts to parents about their child’s missed assignments, grades and class absences. The intervention reduces course failures by 38% and increases class attendance by 17%. Students are more likely to be retained in the district. However, we do not find effects on standardized test scores. Our findings show that automated technology to inform parents can improve student effort relatively cheaply and at scale.",
  "publication_date": "2017-05-01",
  "erct_level": 1,
  "rct": true,
  "criteria": {
    "c": {
      "analysis": "Quotes from the paper regarding randomization and the unit of assignment:\n\n1) “Recruitment was at the household level, and ... random assignment was at the school-by-grade level to minimize the potential for spillovers...” (p. 10)\n2) “We then asked their language preference and preferred modes of contact—text message or phone calls... Randomization into treatment and control was completed in early October 2015.” (p. 6)\n3) “Random assignment was at the school-by-grade level... all school employees were blinded to the randomization process.” (p. 10)\n\nAnalysis:\n(1) The authors clearly state that entire grades within each school were randomly assigned to either treatment or control, not individual students within a single class. While this is not exactly randomizing entire schools, it is still a group-based approach that is larger than just student-level randomization within one classroom. This helps reduce contamination and ensures that whole cohorts are assigned together.\n(2) Because the criterion for ‘Class-level RCT (C)’ is met if randomization is done at the class level or any stronger group level (such as entire grades, entire schools, etc.), the design surpasses a simple within-class or student-level assignment.\n(3) Therefore, the study satisfies the key requirement that the randomization was neither student-by-student nor within the same classroom without any special exception. Instead, it was carried out on a larger group basis.\n",
      "met": true,
      "explanation": "They randomized entire grades in each school, which is larger than a single class and thus meets or exceeds the class-level requirement.",
      "quote": "“Random assignment was at the school-by-grade level… all school employees were blinded…” (p. 10)"
    },
    "e": {
      "analysis": "Quotes from the paper regarding the use of standardized exams:\n\n1) “We obtained administrative data from the district and the gradebook application once again… We also obtained standardized exam scores in math and English…” (p. 7)\n2) “The standardized test scores are from the Smarter Balanced assessment, which is aligned to the Common Core. We received scaled standardized test scores for Math and ELA for 2015 and 2016 examinations.” (p. 8)\n\nAnalysis:\n(1) The authors explicitly mention using the Smarter Balanced assessment (Math and English), a well-known standardized test aligned with the Common Core. This is not a custom researcher-created instrument.\n(2) Because the Smarter Balanced tests are recognized and typically used for broader assessment, the requirement of employing an exam-based assessment is fulfilled.\n(3) The paper does mention that students did not treat these tests as particularly high stakes, but that does not negate their status as standardized, externally developed assessments.\n",
      "met": true,
      "explanation": "They used the Smarter Balanced standardized assessment for math and reading, which is an established exam-based measure.",
      "quote": "“The standardized test scores are from the Smarter Balanced assessment, which is aligned to the Common Core…” (p. 8)"
    },
    "t": {
      "analysis": "Quotes from the paper regarding the duration of the intervention:\n\n1) “Randomization into treatment and control was completed in early October 2015… The intervention ran between the end of October 2015 through the end of May when the school year was expected to conclude.” (p. 6)\n2) “We do not find improvements in standardized math and English test scores… The intervention ended in May 2016.” (pp. 2, 16)\n\nAnalysis:\n(1) The program was in place from approximately late October through late May, which covers around seven months.\n(2) While an academic ‘term’ often approximates a semester (three or four months), the paper’s timeline shows that the study spanned effectively one major part of the school year (fall through spring of the same academic year).\n(3) Because they implemented the intervention across most of a school year, they exceed the minimal threshold of running for at least one academic term.\n",
      "met": true,
      "explanation": "They ran the messaging intervention from late October to May, which is sufficiently long (spanning multiple months) to fulfill a typical academic term duration.",
      "quote": "“The intervention ran between the end of October 2015 through the end of May…” (p. 6)"
    },
    "d": {
      "analysis": "Quotes from the paper describing the control group:\n\n1) “Parents in the control group received the default level of information that the schools and teachers provided… This included report cards… phone calls home from teachers…” (p. 6)\n2) “Randomization… created a treatment and control group that are similar in terms of observable variables; no treatment-control differences are statistically significant at the 10% level.” (p. 11)\n3) “In the school year previous to the study… 44% of students received proficient or better in reading and 29% in math… 83% of district students are identified as white and 12% as Black.” (p. 4)\n\nAnalysis:\n(1) The authors clearly define how the control group was formed (randomized at the school-by-grade level) and state that it received the usual communications such as report cards, conferences, or teacher-initiated phone calls.\n(2) They provide baseline demographic and achievement information for both groups, confirming that the control group’s characteristics are well documented (e.g., race, baseline GPAs, prior attendance, etc.).\n(3) The paper confirms that the control group’s baseline equivalence was tested and that they continued with “business as usual.”\n",
      "met": true,
      "explanation": "They document the control group’s baseline demographics, prior achievement, and standard practices used, confirming a well-described comparison group.",
      "quote": "“Parents in the control group received the default level of information... This included report cards... phone calls home...” (p. 6)"
    },
    "s": {
      "analysis": "Quotes from the paper regarding the randomization level:\n\n1) “Random assignment was at the school-by-grade level to minimize potential spillovers…” (p. 10)\n2) “We used a field experiment in 22 middle and high schools… We randomly assigned each grade within a school to treatment or control.” (pp. 2, 10)\n\nAnalysis:\n(1) The School-level RCT criterion requires that entire schools be the unit of randomization. Here, the authors assigned entire grade levels within each school, rather than assigning the entire school en masse.\n(2) While the approach is larger than single-class randomization, it does not meet the strict requirement of randomizing entire schools. A truly school-level design would have each school entirely in treatment or entirely in control.\n(3) Because they used “school-by-grade” as the randomization unit, they do not fully satisfy the School-level RCT requirement.\n",
      "met": false,
      "explanation": "Randomization was done by grade within each school, not by entire schools as required for S.",
      "quote": "“Random assignment was at the school-by-grade level...” (p. 10)"
    },
    "a": {
      "analysis": "Quotes from the paper regarding subjects measured:\n\n1) “We also obtained standardized exam scores in math and English… We do not find improvements in standardized math and English test scores…” (p. 2)\n2) “The standardized test scores are from the Smarter Balanced assessment, which is aligned to the Common Core. We received scaled standardized test scores for Math and ELA… (p. 8)\n3) “44% of students received proficient-or-better scores in reading and 29%… in math… The district subsequently discontinued using these standardized tests.” (p. 4, 16)\n\nAnalysis:\n(1) To meet ‘AllExams (A),’ the study must assess learning outcomes in all main subjects (or justify a specialized context). Here, the authors focus on math and English test scores and do not address other required core subjects (e.g., science, social studies).\n(2) Despite collecting multiple measures (GPA, assignment completions), only math and ELA standardized test scores are used to evaluate broader outcomes.\n(3) Therefore, the study does not measure all mainstream subjects taught in the school.\n",
      "met": false,
      "explanation": "They assessed only math and reading outcomes, with no coverage of other main subjects such as science or social studies.",
      "quote": "“We received scaled standardized test scores for Math and ELA...” (p. 8)"
    },
    "y": {
      "analysis": "Quotes from the paper regarding duration:\n\n1) “The intervention ran between the end of October 2015 through the end of May…” (p. 6)\n2) “Officially, the academic school year ended in early June… but varied slightly based on weather-induced make-up days.” (p. 6)\n\nAnalysis:\n(1) A full academic year typically spans around 9–10 months (late summer or early fall through late spring). Here, the authors began randomization and launched the text-message alerts in late October, about two months into the school year.\n(2) The intervention ended in late May or early June, which is roughly seven to eight months in total. Although that covers most of the year, it did not start right at the beginning.\n(3) For ‘Y – Year Duration,’ the standard requires a year-long implementation. Their study, while fairly long, does not clearly cover the entire academic year from start to finish.\n",
      "met": false,
      "explanation": "The intervention began around October and ended in late May, which is shorter than a full academic year (roughly 9–10 months).",
      "quote": "“The intervention ran between the end of October 2015 through the end of May when the school year was expected to conclude.” (p. 6)"
    },
    "b": {
      "analysis": "Quotes from the paper regarding resources and time:\n\n1) “The marginal cost of each text message is less than a fraction of one cent… The total cost of all of these messages was approximately $63.” (p. 3)\n2) “Though in principle many learning management systems could be used… if a school were to adopt the entire system in this study and training for how to use it, the cost would be $7 per student.” (p. 22)\n3) “Parents in the control group received the default level of information… The control group did not receive text alerts.” (p. 6)\n\nAnalysis:\n(1) The study’s main ‘extra resource’ is a low-cost automated messaging system. The direct cost per text is negligible, and it does not require significant additional instructional time or budget for teachers or students. No large tutoring sessions or budget outlays are described.\n(2) Because the control group does not receive an equivalent budget or alternative resources, we must consider whether the new resource was big enough to need balancing. The paper indicates the cost per student is minimal.\n(3) The Balanced Control Group requirement typically matters when additional instruction time, tutoring hours, or budget is provided to the treatment group. Here, the intervention is an extremely small financial outlay that the authors argue is “relatively cheap.” However, strictly speaking, the control group did not receive any analogous resource.\n",
      "met": false,
      "explanation": "The intervention group received an added technology (text-message updates). No matching resource or budget/time was provided to the control group, so the control condition was not balanced in resources.",
      "quote": "“The marginal cost of each text message is… $63 total… The control group did not receive text alerts.” (pp. 3, 6)"
    },
    "g": {
      "analysis": "Quotes from the paper on how long participants were tracked:\n\n1) “We do not find improvements in standardized math and English test scores… The intervention ended in May 2016.” (p. 2, 16)\n2) “After the school year concluded we surveyed parents… The survey took place between June and August 2016.” (p. 7)\n\nAnalysis:\n(1) The Graduation Tracking (G) criterion requires following students through to the point of graduation from the current educational level (e.g., middle-school graduation or high-school graduation). In this study, data collection ended near the close of a single school year.\n(2) The authors do not track students beyond that year to see if the effects persist or if they graduate from high school.\n(3) Hence, the paper does not provide evidence of extended long-term follow-up through graduation.\n",
      "met": false,
      "explanation": "They only followed students through the end of that academic year and did not track them until any graduation milestone.",
      "quote": "“The intervention ended in May 2016… We surveyed parents in June… No long-term follow-up.” (pp. 2, 7)"
    },
    "r": {
      "analysis": "Quotes from the paper regarding replication:\n\n1) “Recent research has demonstrated that providing information to parents can produce significant gains… (Bergman, 2014; Kraft & Rogers, 2014; Castleman & Page, 2015)…” (p. 1)\n2) “We helped design and implement an automated-text messaging program… (p. 22)\n\nAnalysis:\n(1) While the authors cite related studies that used text-based interventions, these appear to be separate, prior projects with partially overlapping teams or somewhat different interventions.\n(2) The paper does not describe a fully independent replication in a different context by a different research group.\n(3) Therefore, there is no mention that a separate team has replicated these methods and findings independently.\n",
      "met": false,
      "explanation": "No independent replication is documented in the paper; they do not report another research team reproducing the same results.",
      "quote": "“We helped design and implement an automated-text messaging program… We do not know if this intervention works in other contexts.” (p. 22)"
    },
    "i": {
      "analysis": "Quotes from the paper discussing the research team and authors’ involvement:\n\n1) “Bergman has previously received compensation from the learning management system company to design the technology tested in this study.” (p. 2)\n2) “We partner with a Learning Management System company to develop and test a technology that synchronizes with districts’ SIS…” (p. 1)\n\nAnalysis:\n(1) The Independence criterion requires that the authors or research team not be the same individuals who developed the intervention, or at least have a formal statement of independent evaluation or third-party oversight.\n(2) Here, the main researcher acknowledges prior financial ties to the platform’s creation and direct involvement in designing it.\n(3) Thus, the study is not fully independent of the intervention’s designers.\n",
      "met": false,
      "explanation": "The lead researcher co-developed the intervention and previously received compensation from the LMS company, so it was not independently conducted.",
      "quote": "“Bergman has previously received compensation from the learning management system company to design the technology…” (p. 2)"
    },
    "p": {
      "analysis": "Quotes from the paper regarding pre-registration:\n\n1) The paper does not mention any registry platform, such as ClinicalTrials.gov or OSF, nor does it provide a pre-analysis registration ID.\n2) “In this paper, our survey results demonstrate… We also demonstrate… The rest of the paper proceeds…” (pp. 1-2) — standard exposition, but no mention of a pre-registered protocol.\n\nAnalysis:\n(1) For Pre-Registered (P), the authors must have posted a formal study protocol prior to data collection on a recognized platform or repository. The text does not supply a link or registry ID.\n(2) The authors mention having an ‘analysis plan’ (p. 14 references that it was guided by earlier design choices), but it is not stated to have been publicly registered before the trial.\n(3) Hence, there is no evidence of official pre-registration.\n",
      "met": false,
      "explanation": "The paper does not reference any formal pre-registration or provide a registry ID prior to data collection.",
      "quote": null
    }
  }
}
