{
  "title": "School governance, teacher incentives, and pupil–teacher ratios: Experimental evidence from Kenyan primary schools",
  "authors": "Esther Duflo, Pascaline Dupas, Michael Kremer",
  "url": "https://doi.org/10.1016/j.jpubeco.2014.11.008",
  "slug": "duflo-dupac-kremer-2015-kenya-contract-teachers",
  "abstract": "This paper investigates a program under which randomly selected Kenyan schools were funded to hire an additional contract teacher, outside of the normal civil-service channels, alongside a parallel governance intervention that empowered parents in the hiring and monitoring process. The authors examine whether extra teachers and local governance reforms can work as complements in improving test scores and reducing class size. Results show a positive effect on test scores only for pupils assigned to locally hired contract teachers, especially when parents were formally empowered to supervise them. However, these short-term gains faded out once the intervention ended.",
  "publication_date": "2015-01-01",
  "erct_level": 0,
  "rct": true,
  "criteria": {
    "c": {
      "analysis": "The paper describes random assignment of entire schools to receive the Extra Teacher Program (ETP) or to serve as a control, as seen in: “The ETP program provided 70 randomly selected school committees with funds to hire an additional teacher…” (p. 93). The authors also note: “We set up an experiment… a randomized evaluation of the Extra Teacher Program…” (p. 93). Although the study further randomly assigned students within the same school to classes, the crucial point is that entire schools were randomly chosen to participate. This meets or surpasses the requirement of class-level randomization, since randomization at the school level is even stronger than randomizing classes within a school. \n\nThey discuss the sample design in detail, explaining that out of 210 schools in the area, “70 were randomly divided into a comparison group…, and 140 into ETP groups…” (pp. 94-95). This confirms that the unit of assignment was at least at the school level. \n\nHence, randomization is clearly described and properly implemented, and it does not appear that the treatment was merely assigned at the individual-student level within the same classroom (in a single class). The authors are explicit that the key randomization for the intervention itself was at the school level. \n\nTherefore, the paper fulfills the Class-level RCT criterion (C) because the unit of randomization was at the school level (which is acceptable as an equivalent or stronger design).",
      "met": true,
      "explanation": "They conducted a randomized assignment of entire schools to the Extra Teacher Program, which meets or exceeds class-level RCT requirements.",
      "quote": "“The ETP program provided 70 randomly selected school committees with funds to hire an additional teacher…We set up an experiment…” (pp. 93-94)"
    },
    "e": {
      "analysis": "The ERCT criterion E requires the use of a widely recognized, standardized exam-based assessment (e.g., a national exam) rather than a custom test tailored only to the intervention. The paper notes that the authors administered “standardized tests covering math and literacy questions ranging from identifying numbers and letters to subtracting two-digit numbers…” (p. 97). However, it appears these tests were specifically created or adapted by the research team for this evaluation, rather than a pre-existing national or official external test like Kenya’s KCPE or a recognized international test. \n\nThey write: “In each school, 60 students were randomly drawn from the baseline sample to participate in the tests. Standardized tests covering math and literacy…were administered…” (p. 97). While the tests were consistent across study schools, the paper does not claim they were from any recognized external body, nor do they mention widely accepted psychometric validity from a national education authority. \n\nHence, these appear to be researcher-created tests with internal consistency but not a standard, widely recognized exam. Therefore, it does not fulfill the specific requirement of a well-established external exam. \n\nAs a result, the exam-based assessment (E) criterion, which mandates that the study measure outcomes using widely recognized standardized tests, is not met.",
      "met": false,
      "explanation": "They used a study-specific math and literacy test, not a widely recognized external standardized exam.",
      "quote": "“Standardized tests covering math and literacy questions… were administered in all schools after 5 school terms… [T]rained enumerators and a separate team graded them.” (p. 97)"
    },
    "t": {
      "analysis": "The requirement T is that the intervention run for at least one full academic term, typically 3-4 months. The authors describe a program spanning multiple terms: “We examine how these two approaches… in the context of a randomized evaluation of the Extra Teacher Program (ETP) implemented in Kenya between 2005 and 2007.” (p. 93). \n\nThey specifically state that “the program was implemented… over a two year period” (pp. 94-95). Later they clarify that the new contract teacher was hired in early May 2005 and continued through the remainder of the 2005 school year and beyond, up to November 2006. \n\nThus the intervention covered at least a year and a half of active implementation, spanning multiple school terms. This substantially exceeds the minimal threshold of a single academic term. \n\nHence the T criterion is satisfied.",
      "met": true,
      "explanation": "They implemented the program for at least 18 months (across multiple academic terms), easily surpassing the minimum term requirement.",
      "quote": "“All but two of the 70 schools… had a contract teacher in place by early May 2005… data on test scores were collected in November 2006…” (pp. 94, 97)"
    },
    "d": {
      "analysis": "The D criterion requires that the control group be well documented: describing its baseline characteristics, demographic details, and the nature of instruction. The authors clearly identify a control group of 70 schools that did not receive extra teachers or the parent empowerment training. They compare background data between these control schools and the ETP schools: “Background data on enrollment, pupil–teacher ratios, and number of grade 1 sections was collected in 2004 from 210 primary schools… The 210 schools were randomly divided into… an Extra Teacher Program (ETP) group (140 schools) [and] a comparison group (70 schools).” (p. 94). \n\nThey also describe how the control schools’ class sizes and other relevant features were measured, providing baseline equivalences in Table 1. These tables detail exam scores, enrollment, number of TSC teachers, and teacher gender composition (pp. 96-97). \n\nFurthermore, the authors discuss the typical practice in these control schools, which “continued under the usual Ministry of Education system, with pupil–teacher ratios frequently above 70 or 80 in Grade 1” (pp. 92-93). \n\nThus the control group is thoroughly documented in terms of baseline data and how they continued with ‘business as usual.’ The study meets the requirement for a clearly documented control group.",
      "met": true,
      "explanation": "They clearly described the control group’s composition (70 schools), baseline data, class sizes, and normal teaching practices.",
      "quote": "“Background data… was collected in 2004… The 210 schools were randomly divided… 70 schools formed the comparison group.” (p. 94, Table 1)"
    },
    "s": {
      "analysis": "S means randomization must occur at the school level, a stronger requirement than only randomizing classes. Here, the paper explicitly states: “210 primary schools… were randomly divided into a comparison group (70 schools), and an Extra Teacher Program (ETP) group (140 schools).” (p. 94). \n\nBecause entire schools were the unit of assignment, the study does indeed meet or exceed school-level randomization. The authors repeatedly describe how each school was designated a ‘treatment or control’ status. \n\nThus, the S criterion – that entire schools (not just classes) were randomly assigned – is fulfilled here.",
      "met": true,
      "explanation": "They assigned entire schools to the program or control condition, satisfying or exceeding the requirement for school-level RCT.",
      "quote": "“We set up an experiment… The ETP program provided 70 randomly selected school committees with funds… out of 210.” (pp. 93-94)"
    },
    "a": {
      "analysis": "A requires that the study measure outcomes in all main subjects taught in that educational setting, typically to detect negative spillovers in non-targeted subjects. In this paper, the outcomes measured were primarily “standardized tests covering math and literacy questions…” (p. 97). \n\nThe focus is thus on numeracy and language skills. There is no indication that they tested science, social studies, or other subjects in Kenya’s standard primary curriculum. Indeed, the authors note: “Results show a positive effect on test scores only for pupils assigned to locally hired contract teachers… This was measured on math and literacy tests…” (pp. 92, 98). \n\nHence, they did not assess all core subjects such as social studies, science, or other typical areas. They focus on math and literacy only. Consequently, the AllExams requirement is not met. \n\nNo mention is made of a justification for exclusively testing math and literacy at the expense of other main subjects, so the ‘exception for specialized interventions’ does not apply. Therefore, the A criterion is not satisfied.",
      "met": false,
      "explanation": "They only measured math and literacy outcomes, not all main subjects in the curriculum.",
      "quote": "“Standardized tests covering math and literacy questions…we find large differences… we do not see mention of science or other subjects.” (p. 97)"
    },
    "y": {
      "analysis": "Y requires that the intervention last at least one full academic year. As indicated above, “The ETP program… implemented in 2005 and 2006… providing 70 randomly selected school committees… for a two-year period” (pp. 93-94). \n\nThey describe that “Teachers were hired by early May 2005 and… outcomes were tested in November 2006,” so the program covered at least a year and a half of actual classroom implementation. This is well over a single academic year. \n\nThus the Y requirement is fulfilled, as the students remained under the intervention (extra contract teacher or control) for more than one school year. The paper clarifies that classes continued from the second term of 2005 into the second grade in 2006. \n\nHence Y is met.",
      "met": true,
      "explanation": "They ran the Extra Teacher Program for roughly 18–19 months, clearly exceeding the requirement of one school year.",
      "quote": "“ETP was implemented… from May 2005 through November 2006, covering at least 3 school terms or more.” (pp. 94, 97)"
    },
    "b": {
      "analysis": "B requires that if the intervention group receives extra resources (e.g., additional teachers, training, or budget), the control group should receive an equivalent resource/time allocation so any difference is purely the intervention method. In this study, the treatment schools hired an extra teacher at partial cost, thus halving class size for some children, but the control schools received no equivalent resource. \n\nIn fact, the authors repeatedly note that the control schools simply carried on with their usual large classes: “For students… in comparison schools, class size remained extremely high (about 82 in grade 1)…” (p. 96). There is no mention that the control group was given an alternative use of an equivalent budget or additional teaching staff. \n\nHence, the resources are not balanced between treatment and control. The extra teacher’s salary, professional support, and presence is a direct addition in the ETP schools, while the control schools have no matching fund or added staff time. \n\nConsequently, the Balanced Control Group (B) criterion is not met.",
      "met": false,
      "explanation": "Only the ETP schools received funds to hire contract teachers, while the control schools did not receive a corresponding resource offset.",
      "quote": "“…the control group continued under standard instruction with no additional teacher… (class size ~82) whereas the ETP group hired an extra teacher…” (pp. 92, 96)"
    },
    "g": {
      "analysis": "G (Graduation Tracking) requires the study to follow students until they graduate their current school level (e.g., end of primary). Here, data collection ended after about 19 months (November 2006) and an additional follow-up about a year later, but the authors specifically mention that they did not track students through to the completion of their entire primary education. \n\nThey write: “One year after the program ended… a follow-up test was administered,” but do not indicate that children were observed until they finished primary school. The study instead focuses on short-run test score improvements and teacher effort changes. \n\nTherefore, they did not measure graduation outcomes nor track the cohort through the end of primary. Hence, G is not met. \n\nNo quotes reference collecting data on final primary-school completion or post-primary follow-up, so the criterion is not satisfied.",
      "met": false,
      "explanation": "They tested students at 19 months and then a year later, but did not track them until graduation from primary school.",
      "quote": "“The same tests were administered again… one year after the program ended (November 2007).” (p. 99) No mention of following them through primary completion."
    },
    "r": {
      "analysis": "R requires that another research team replicate the study independently, ideally in another context. The authors do not mention any external group replicating this specific contract-teacher plus governance design in different schools or times with the same research protocol. \n\nWhile they do mention that “a separate set of schools were chosen for an alternative Extra Teacher Program” (p. 94) and refer to some related India-based research by Muralidharan and Sundararaman (2013), none of this is described as an independent replication by a different team. \n\nHence, the paper does not demonstrate that the same design was separately reproduced by a different research group. Therefore, the Reproduced criterion (R) is not met.",
      "met": false,
      "explanation": "They reference related contract teacher studies, but not an independent replication of their specific design by a separate research team.",
      "quote": "“A separate set of schools were chosen for an alternative… (p. 94) … We also note Muralidharan & Sundararaman (2013) in India, but that is not an explicit replication.”"
    },
    "i": {
      "analysis": "I requires that the study be conducted independently, meaning the authors who designed the intervention should not be the same team implementing data collection and analysis, or at least that there was explicit third-party oversight. In this paper, the authors (affiliated with MIT, Stanford, Harvard, etc.) partnered with an NGO called International Child Support (ICS) for implementation. However, the authors indicate they were central in designing and setting up the randomized evaluation: “We examine a program… We set up an experiment…” (p. 93). \n\nAlthough ICS is a separate group, the paper does not state that ICS or any other outside firm fully handled all research procedures or data analysis independently. Indeed, the authors appear to be the prime drivers of design and analysis. They do not mention an external, unaffiliated entity verifying or auditing the research. \n\nThus, it does not clearly satisfy the requirement that the study be conducted and analyzed entirely independently from the intervention’s principal investigators. We do not see a statement such as “Data collection and analysis were done by an external evaluation team with no involvement from the authors.” \n\nHence, the Independence (I) criterion is not met.",
      "met": false,
      "explanation": "The authors themselves set up the experiment and carried out the analysis; no explicit independent external team was described.",
      "quote": "“We set up an experiment… ICS staff met with the headmaster… but the authors appear to lead design and research.” (p. 93)"
    },
    "p": {
      "analysis": "P requires that the study be pre-registered, meaning the authors publicly posted a pre-analysis plan before collecting data. The paper does not mention any pre-registration platform (e.g., the AEA RCT Registry or clinicaltrials.gov). \n\nThey do not provide a date or any reference number for the registration, nor do they claim that the analysis adhered to a previously deposited protocol. \n\nTherefore, the P requirement is not satisfied.",
      "met": false,
      "explanation": "No mention is made of any pre-registration or a publicly accessible, time-stamped analysis plan.",
      "quote": null
    }
  }
}
