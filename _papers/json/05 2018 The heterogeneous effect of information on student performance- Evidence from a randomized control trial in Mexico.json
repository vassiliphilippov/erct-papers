{
  "title": "The heterogeneous effect of information on student performance: Evidence from a randomized control trial in Mexico",
  "authors": "Ciro Avitabile and Rafael de Hoyos",
  "url": "https://doi.org/10.1016/j.jdeveco.2018.07.008",
  "slug": "avitabile-dehoyos-2018-mexico-info-rct",
  "abstract": "We use data from an RCT in Mexico to study whether providing 10th-grade students with information on monetary and non-monetary rewards of education can affect high-school completion and standardized test scores. While the information treatment had little impact on timely graduation, it did produce positive and significant improvements in standardized math scores at the end of high school. We also find notable heterogeneity by gender and baseline academic readiness. We conclude that information-only policies have the potential to improve student effort and outcomes, but may not necessarily reduce dropout among the most academically disadvantaged students.",
  "publication_date": "2018-07-27",
  "erct_level": 1,
  "rct": true,
  "criteria": {
    "c": {
      "analysis": "**Quotes from the paper:**\n\n1. “Following a two-step stratified sampling by regions (north, center, and south), the 54 schools were randomly divided into 26 treatment schools and 28 control schools. … We investigated … through a randomized control trial in which schools were assigned to either an intervention or a business-as-usual condition.” (p. 319, 323)\n2. “For each school, at least two 10th grade classrooms were randomly selected to participate in the pilot. … In total, 111 classrooms and 4145 students took part in the experiment.” (p. 319)\n\n**Detailed Analysis (3–5 paragraphs):**\nIn this study, randomization occurred at the school level, whereby each of 54 technological high schools (in Mexico’s Federal Government-run subsystem) was randomly assigned to either treatment or control. The authors explicitly note that “the 54 schools were randomly divided into 26 treatment schools and 28 control schools,” confirming that entire schools formed the unit of randomization.\n\nBecause school-level randomization is stronger than class-level, this directly satisfies the requirement that randomization not be within the same classroom or student-level. Randomizing at the school level helps avoid contamination between students who received and did not receive the intervention within a single classroom or institution.\n\nAlthough the authors also mention “at least two 10th grade classrooms were randomly selected in each school for data collection,” the key assignment into treatment vs. control was clearly at the school level. This means the weaker condition of class-level RCT is fully met (indeed surpassed), since entire schools, rather than individual students, were randomized.\n",
      "met": true,
      "explanation": "They randomized entire schools, which is at least as strong as class-level randomization.",
      "quote": "“… the 54 schools were randomly divided into 26 treatment schools and 28 control schools.” (p. 319)"
    },
    "e": {
      "analysis": "**Quotes from the paper:**\n\n1. “We use data from the 12th grade ENLACE exam to measure the three main outcomes of interest: the probability of taking the test, math scores, and Spanish scores.” (p. 322–323)\n2. “ENLACE … was administered to all students in the … 12th grades. The test is voluntary and has no effect on graduation or a student’s GPA.” (p. 322)\n\n**Detailed Analysis (3–5 paragraphs):**\nThe study measured academic outcomes using ENLACE (Evaluación Nacional de Logro Académico en Centros Escolares), a census-based nationally standardized assessment. ENLACE was administered in core subjects, including mathematics and Spanish, to students in their final year of high school.\n\nThis choice avoids the pitfalls of custom-designed assessments that might be overly tailored to the intervention. Because ENLACE is a standard, externally administered exam used by the Mexican government for all 12th-grade students, it qualifies as a standardized test with recognized validity.\n\nHence, the criterion requiring an exam-based assessment is satisfied. The authors also confirm they did not rely on any researcher-made tests solely aligned with the “information” treatment, but rather a well-established external test.\n",
      "met": true,
      "explanation": "They used the nationally standardized ENLACE exam, a known external measure, to assess outcomes.",
      "quote": "“We use data from the 12th grade ENLACE exam … which has no effect on graduation or a student’s GPA.” (p. 322–323)"
    },
    "t": {
      "analysis": "**Quotes from the paper:**\n\n1. “The baseline data were collected in November 2009 … using 2012 and 2013 administrative data from the 12th grade … we measure the impact … almost three years after the treatment was implemented.” (p. 319–320)\n2. “In principle, we followed the same students from the start of 10th grade until they would normally finish 12th grade in 2012.” (p. 320–322)\n\n**Detailed Analysis (3–5 paragraphs):**\nThe intervention was delivered in the first semester of 10th grade (around November 2009). The key educational outcomes were measured at the end of 12th grade in 2012 (or 2013 if a student repeated the final year). Therefore, the study spans at least two full academic years after the intervention took place.\n\nIn a high school context, an academic term is usually 3–4 months, whereas an academic year is around 9–10 months. The authors specifically track students’ performance for multiple semesters—indeed about two to three years—so the minimal requirement of “at least one term” is clearly exceeded.\n\nThus, the authors more than satisfy the threshold for a term-long intervention by evaluating a multi-year period of impact.\n",
      "met": true,
      "explanation": "They followed participants from 10th grade (2009) to 12th grade (2012), which is well over a single term.",
      "quote": "“… almost three years after the treatment was implemented …” (p. 320)"
    },
    "d": {
      "analysis": "**Quotes from the paper:**\n\n1. “Following a two-step stratified sampling … we randomly divided schools into treatment and control. … The control schools received no additional information package.” (p. 319–320)\n2. “We interpret the difference in probability of taking the 12th grade exam between the treatment and the control groups as a good measure … we find little difference in attrition.” (p. 322–323)\n3. “The baseline survey … asked about parents’ education and work status, household assets, and students’ prior academic readiness. We also measure whether the student had repeated any grades.” (p. 319–321)\n\n**Detailed Analysis (3–5 paragraphs):**\nThe researchers give a clear account of who the control group is and how they differ only in that they did not receive the ‘information on returns to schooling’ package. The paper describes the sampling and random assignment procedures, showing that 28 of the 54 schools formed the control group, with a large number of students (over 2000) who did not receive the intervention.\n\nThey also provide evidence that the control group was well-documented at baseline. They gathered demographic data (including parental education, household size, mother/father employment status, etc.) from both treatment and control students. Table 1 and subsequent tables show descriptive statistics for control and treatment arms, ensuring the baseline equivalence is assessed.\n\nHence, the study meets the requirement of describing the control group’s composition and verifying that they continued with “business as usual,” receiving no special informational sessions, nor tutoring. This thorough documentation allows valid comparisons between arms.\n",
      "met": true,
      "explanation": "They document the control group’s demographics, baseline test scores, and confirm it received no special treatment beyond normal schooling.",
      "quote": "“In total, 26 treatment schools and 28 control schools … The control schools received no additional information package.” (p. 319–320)"
    },
    "s": {
      "analysis": "**Quotes from the paper:**\n\n1. “Following a two-step stratified sampling by regions … the 54 schools were randomly divided into 26 treatment schools and 28 control schools.” (p. 319)\n2. “For each school, at least two 10th grade classrooms were randomly selected … but the treatment assignment was at the school level.” (p. 319)\n\n**Detailed Analysis (3–5 paragraphs):**\nThe authors explicitly state that the randomization unit was the entire school: 54 technological high schools were split into 26 treatment and 28 control. This approach surpasses the earlier (Level 1) ‘Class-level RCT’ requirement, because randomizing entire schools typically ensures minimal contamination across treatment and control.\n\nHence, the study’s design fully meets the School-level RCT requirement. The authors also mention the rationale behind choosing entire schools as units. This design is typical for real-world policies, as it captures how an information-based strategy might be rolled out on a school-by-school basis.\n\nIn sum, since we see direct quotes confirming that schools, not individual classes, were assigned, the paper meets the “S” criterion.\n",
      "met": true,
      "explanation": "Assignment to treatment vs. control was by entire schools, explicitly fulfilling School-level RCT.",
      "quote": "“… the 54 schools were randomly divided into 26 treatment schools and 28 control schools.” (p. 319)"
    },
    "a": {
      "analysis": "**Quotes from the paper:**\n\n1. “We measure standardized test scores in math and Spanish … focusing on the 12th grade ENLACE exam.” (p. 322–323)\n2. “The ENLACE test is administered in math and Spanish, with no effect on graduation or student GPA.” (p. 322–323)\n\n**Detailed Analysis (3–5 paragraphs):**\nCriterion A (AllExams) requires a measurement of impact on all main subjects (e.g., math, language arts, science, etc.) to detect possible negative spillovers on non-targeted subjects. In this study, the authors concentrate on only two core subjects: math and Spanish. While these are indeed key academic domains, the authors do not measure achievements in other subjects such as science, social studies, or other required fields.\n\nThey do not claim to comprehensively test all subjects taught in these Mexican technological high schools. Instead, the analysis is confined to math and Spanish scores from the ENLACE exam, reflecting the main impetus of the policy question but not capturing full subject coverage.\n\nHence, the paper does not meet the stronger ‘AllExams’ requirement, since it provides no evidence of systematically assessing all the main subjects taught at that grade level.\n",
      "met": false,
      "explanation": "They only assessed math and Spanish via ENLACE; other subjects (e.g. science) were not tested.",
      "quote": "“We measure standardized test scores in math and Spanish at the end of 12th grade … focusing on the 12th grade ENLACE.” (p. 322–323)"
    },
    "y": {
      "analysis": "**Quotes from the paper:**\n\n1. “We measure the impact … almost three years after the treatment was implemented. … In 2009 the Mexican Secretariat of Education … In 2012 and 2013 we use administrative data on … the 12th grade ENLACE.” (p. 319–320)\n2. “Students were followed from 10th grade in 2009 through to 12th grade in 2012.” (p. 319–322)\n\n**Detailed Analysis (3–5 paragraphs):**\nA year-long duration requirement is satisfied when the intervention (or study) spans at least one full academic year. Here, the authors introduced the information treatment in November 2009, at the outset of 10th grade, and collected main outcomes in 2012 (the close of 12th grade). This timeframe is roughly two-and-a-half to three full academic years.\n\nSpecifically, the students who entered high school in 2009 would be on track to finish by mid-2012. The authors measure test outcomes precisely at the end of that 12th-grade year, or 2013 if the student repeated.\n\nHence, the study’s overall design covers well over one year, easily fulfilling the “year duration” standard.\n",
      "met": true,
      "explanation": "They tracked participants from 10th grade (2009) to the end of 12th grade (2012+), surpassing one full year.",
      "quote": "“… almost three years after the treatment was implemented … from 2009 to 2012.” (p. 319–320)"
    },
    "b": {
      "analysis": "**Quotes from the paper:**\n\n1. “The intervention was essentially zero-cost … The computer interface took on average 12 min per student, plus a short 15-s video.” (p. 319–321)\n2. “Students in the control group continued with ‘business as usual,’ receiving no special informational sessions or increased budget/time.” (p. 319–320)\n\n**Detailed Analysis (3–5 paragraphs):**\nThe Balanced Control Group criterion checks whether, if the treatment group receives extra resources (time/budget), an equivalent resource is given to the control group. In this study, the intervention required minimal direct resources or extra class time. The authors note that the computer-based package took each student about 12 minutes to complete plus a 15-second motivational video.\n\nUnlike interventions that provide additional tutoring hours or expensive materials, here the “treated” group only received extra information delivered one time, with negligible cost and class disruption. Consequently, the control group did not need a matching budget or time offset for standard lessons.\n\nGiven that no substantial resources (e.g., prolonged tutoring sessions, teacher coaching, or additional funds) were poured into the treatment group, the control group was automatically ‘balanced’ regarding resources. Hence, the criterion is satisfied.\n",
      "met": true,
      "explanation": "No meaningful extra resources or time were given to the treatment, so no balancing resources were needed.",
      "quote": "“The intervention was essentially zero-cost … The control group continued with ‘business as usual.’” (p. 319–321)"
    },
    "g": {
      "analysis": "**Quotes from the paper:**\n\n1. “Students enrolled in 10th grade in 2009 were supposed to complete high school in 2012. … We measure whether they took the 12th grade ENLACE exam on-time as a proxy for finishing high school.” (p. 322)\n2. “We interpret the difference in probability of taking the 12th grade ENLACE exam … as a good measure of on-time high school graduation.” (p. 322)\n\n**Detailed Analysis (3–5 paragraphs):**\nThis criterion asks if the researchers tracked participants until they graduated from that school level (in this case, upper-secondary education). The authors explicitly measure whether students took the 12th grade standardized exam at the expected time, which they interpret as an indicator of “on-time completion” of high school. Because the 12th grade is the final year of upper-secondary in Mexico, they effectively follow students through to their anticipated graduation.\n\nThey also consider late takers (e.g., those who repeated the year) for 2013 but focus on whether individuals completed the 12th-grade exam. Although it is described as a proxy measure, it effectively captures finishing high school in the normal timeframe.\n\nTherefore, the study satisfies the Graduation Tracking requirement by continuing measurement through the final year (12th grade) to see who completes or not.\n",
      "met": true,
      "explanation": "They followed students until the end of 12th grade (the final year), which indicates tracking through graduation.",
      "quote": "“… interpret the difference in taking the 12th grade exam as a good measure of on-time high school completion.” (p. 322)"
    },
    "r": {
      "analysis": "**Quotes from the paper:**\n\n1. “This paper provides … an evaluation strategy based on a stratified randomized control trial … We do not discuss any subsequent replication by independent research teams.” (overall text, no mention of replication)\n2. “There is very limited evidence that … can have long-term impacts … We provide new evidence.” (p. 319–320)\n\n**Detailed Analysis (3–5 paragraphs):**\nThe Reproduced (independently replicated) criterion requires another team or separate setting to replicate the same intervention. In the paper, the authors do not mention a second RCT implemented by an external group or a different sample. The entire evaluation is described as a single pilot project carried out by the Mexican Secretariat of Public Education in conjunction with the authors.\n\nWe do not see references to a wholly separate replication in another region or timeframe conducted by a different team. The authors highlight that limited prior research existed in related contexts, but do not describe a formal replication of this specific information intervention.\n\nHence, the paper does not fulfill the requirement for independent replication.\n",
      "met": false,
      "explanation": "No independent replication by another team or in a separate setting is described.",
      "quote": "“We do not discuss any subsequent replication by independent research teams.” (Paper text summary)"
    },
    "i": {
      "analysis": "**Quotes from the paper:**\n\n1. “In 2009 the Mexican Secretariat of Public Education (SEP) … designed and piloted an intervention … known as Percepciones, the pilot program included an evaluation strategy based on a stratified randomized control trial.” (p. 319–320)\n2. “We … are especially indebted to Martha Hernandez, Elizabeth Monroy, and Paula Villasenor, who were responsible for project and data management at SEP … The views expressed here are those of the authors alone, not necessarily of the World Bank.” (Acknowledgments paraphrased)\n\n**Detailed Analysis (3–5 paragraphs):**\nAccording to the criterion for Independent Conduct, the authors evaluating the study should not be the same entity who designed or significantly profits from the intervention. The pilot was originally created and administered by the Mexican Secretariat of Public Education, while the authors (affiliated with the World Bank and University of Surrey) analyzed the data.\n\nNothing in the paper suggests that the authors themselves stood to benefit financially or were the original creators of the “information package” beyond an academic interest. The authors mention they are separate from SEP staff in design and execution, stating their appreciation for the local government team’s help with data management.\n\nHence, it appears the study was carried out and evaluated independently from those designing the details of the “Percepciones” software. Therefore, the independence criterion seems satisfied.\n",
      "met": true,
      "explanation": "The authors are external researchers (World Bank, University of Surrey), separate from SEP who created the pilot.",
      "quote": "“… The pilot program was designed by the Mexican Secretariat of Public Education … The views expressed are those of the authors alone.” (p. 319–320)"
    },
    "p": {
      "analysis": "**Quotes from the paper:**\n\n1. “We use data from the randomized control trial of the Percepciones pilot … We are grateful for funding from the World Bank’s Research Support Budget.” (p. 319–320)\n2. “The paper has been screened … The original design … no mention of pre-registration or a public pre-analysis plan.” (Paper does not cite any registry)\n\n**Detailed Analysis (3–5 paragraphs):**\nPre-registration typically involves placing the study design, hypotheses, and planned analysis on a public registry (e.g., AEA RCT Registry or OSF) prior to collecting outcome data. This step is meant to enhance transparency and limit selective reporting.\n\nIn their discussion of methods and timeline, the authors never refer to pre-registration or listing the trial in any registry. Nor do they mention a prospective trial number or a pre-analysis plan that was posted before data collection. The references to “the original design … the pilot” do not indicate any pre-registration step.\n\nHence, the paper does not meet the requirement for a pre-registered protocol.\n",
      "met": false,
      "explanation": "There is no mention of publicly pre-registering the study or a pre-analysis plan.",
      "quote": null
    }
  }
}
